---
source_url: https://www.anthropic.com/news/anthropic-and-the-department-of-defense-to-advance-responsible-ai-in-defense-operations
source_type: sitemap
content_hash: sha256:73d11b27cf1cf47c421d24cda5a827b53708cef190e287970eb8491e99c464ca
sitemap_url: https://www.anthropic.com/sitemap.xml
fetch_method: html
published_at: '2025-07-14'
---

Announcements

# Anthropic and the Department of Defense to advance responsible AI in defense operations

Jul 14, 2025

The U.S. Department of Defense (DOD), through its Chief Digital and Artificial Intelligence Office (CDAO), has awarded Anthropic a two-year prototype other transaction agreement with a $200 million ceiling. As part of the agreement, Anthropic will prototype frontier AI capabilities that advance U.S. national security.

"This award opens a new chapter in Anthropic’s commitment to supporting U.S. national security, which is where our earliest federal deployments began more than a year ago,” said Thiyagu Ramasamy, Anthropic's Head of Public Sector. "We look forward to deepening our collaboration across the Department to solve critical mission challenges through our technical expertise, products like our Claude Gov models and accredited Claude for Enterprise offerings, and leadership in safe and responsible AI.”

With CDAO and other DOD organizations and commands, we'll engage in:

* Working directly with the DOD to identify where frontier AI can deliver the most impact, then developing working prototypes fine-tuned on DOD data
* Collaborating with defense experts to anticipate and mitigate potential adversarial uses of AI, drawing on our advanced risk forecasting capabilities
* Exchanging technical insights, performance data, and operational feedback to accelerate responsible AI adoption across the defense enterprise

## Our commitment to responsible AI deployment

At the heart of this work lies our conviction that the most powerful technologies carry the greatest responsibility. We're building AI systems to be reliable, interpretable, and steerable precisely because we recognize that in government contexts, where decisions affect millions and stakes couldn't be higher, these qualities are essential.

We believe democracies must work together to ensure AI development strengthens democratic values globally by maintaining technological leadership to protect against authoritarian misuse.

## Building on a strong foundation of government partnerships

Our commitment to responsible AI deployment, including rigorous safety testing, collaborative governance development, and strict usage policies, makes Claude uniquely suited for sensitive national security applications.

This agreement with CDAO builds upon Anthropic's growing ecosystem of public sector deployments. Last week, we [announced](https://www.anthropic.com/news/lawrence-livermore-national-laboratory-expands-claude-for-enterprise-to-empower-scientists-and) that Lawrence Livermore National Laboratory will make advanced AI capabilities available to over 10,000 scientists, researchers, and staff. LLNL's expansion of Claude access will help bolster research across nuclear deterrence, energy security, and materials science.

We’ve accelerated mission impact across U.S. defense workflows with partners like Palantir, where Claude is integrated into mission workflows on classified networks. This has enabled U.S. defense and intelligence organizations with powerful AI tools to rapidly process and analyze vast amounts of complex data.

[Claude Gov models](https://www.anthropic.com/news/claude-gov-models-for-u-s-national-security-customers), which we custom built for national security customers, already power deployments by agencies across the national security community atop infrastructure powered by Amazon Web Services(AWS).

Organizations interested in transforming their operations with Claude can [contact our public sector team](mailto:pubsec@anthropic.com) to learn more and get started.


<!-- Content filtered: site navigation/footer -->
