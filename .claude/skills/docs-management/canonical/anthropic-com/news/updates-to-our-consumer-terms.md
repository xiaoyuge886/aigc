---
source_url: https://www.anthropic.com/news/updates-to-our-consumer-terms
source_type: sitemap
content_hash: sha256:9ff527ba321d2081ef5ce4b9526f0281e5c39f85374ad77d9f24b71af95c6b65
sitemap_url: https://www.anthropic.com/sitemap.xml
fetch_method: html
published_at: '2025-08-28'
---

Product

# Updates to Consumer Terms and Privacy Policy

Aug 28, 2025

![](https://www-cdn.anthropic.com/images/4zrzovbb/website/653e7474811cf768b6b0f628e253f98c60e2747e-1000x1000.svg)

Today, we're rolling out updates to our Consumer Terms and Privacy Policy that will help us deliver even more capable, useful AI models. We're now giving users the choice to allow their data to be used to improve Claude and strengthen our safeguards against harmful usage like scams and abuse. Adjusting your preferences is easy and can be done at any time.

These updates apply to users on our Claude Free, Pro, and Max plans, including when they use Claude Code from accounts associated with those plans. They do **not** apply to services under our Commercial Terms, including Claude for Work, Claude for Government, Claude for Education, or API use, including via third parties such as Amazon Bedrock and Google Cloud’s Vertex AI.

By participating, you’ll help us improve model safety, making our systems for detecting harmful content more accurate and less likely to flag harmless conversations. You’ll also help future Claude models improve at skills like coding, analysis, and reasoning, ultimately leading to better models for all users.

You’re always in control of this setting and whether we use your data in this way. If you’re a new user, you can select your preference in the signup process. Existing users will see the choice in a pop-up window like the one below.

![App screen showing the modal presented to users](https://www-cdn.anthropic.com/images/4zrzovbb/website/0d48d7f71fe2b5ccc537b48394313a91636bb329-3840x2160.png)

In-app notification for existing Claude app users

Starting today, we’re rolling out notifications so you can review these updates and manage your settings. If you’re an existing user, you have until October 8, 2025 to accept the updated Consumer Terms and make your decision. If you choose to accept the new policies now, they will go into effect immediately. These updates will apply only to new or resumed chats and coding sessions. After October 8, you’ll need to make your selection on the model training setting in order to continue using Claude. You can change your choice in your [Privacy Settings](https://claude.ai/redirect/website.v1.NORMALIZED/settings/data-privacy-controls) at any time.

## Extended data retention

We are also extending data retention to five years, if you allow us to use your data for model training. This updated retention length will only apply to new or resumed chats and coding sessions, and will allow us to better support model development and safety improvements. If you delete a conversation with Claude it will not be used for future model training. If you do not choose to provide your data for model training, you’ll continue with our existing 30-day data retention period.

The new five-year retention period will also apply to [feedback](https://privacy.anthropic.com/en/articles/10023548-how-long-do-you-store-my-data) you submit to us about Claude’s responses to prompts.

To protect users’ privacy, we use a combination of tools and [automated processes](https://www.anthropic.com/research/clio) to filter or obfuscate sensitive data. We do not sell users’ data to third parties.

You can find more details about the Consumer Terms and Privacy Policy updates in our FAQ section below.

#### FAQ

#### What’s changing?

* We will train new models using data from Free, Pro, and Max accounts **when this setting is on** (including when you use Claude Code from these accounts).
  + If you’re a current user, you can select your preference now and your selection will immediately go into effect. This setting will only apply to new or resumed chats and coding sessions on Claude. Previous chats with no additional activity will not be used for model training. You have until **October 8, 2025** to make your selection.
  + If you’re a new user, you can pick your setting for model training during the signup process.
  + You can change your selection at any time in your [Privacy Settings](https://claude.ai/settings/data-privacy-controls).
* We are also expanding our data retention period to five years if you allow us to use your data for model improvement, with this setting only applying to new or resumed chats and coding sessions. If you don't choose this option, you will continue with our existing 30-day data retention period.

These updates **do not apply** to services under our Commercial Terms, including:

* Claude for Work, which includes our Team and Enterprise plans
* Our API, Amazon Bedrock, or Google Cloud’s Vertex API
* Claude Gov and Claude for Education

#### Why are you making this change?

All large language models, like Claude, are trained using large amounts of data. Data from real-world interactions provide valuable insights on which responses are most useful and accurate for users. For example, when a developer debugs code by collaborating with an AI model, that interaction offers valuable signals that help improve future models on similar coding tasks. This creates a feedback loop that helps models get better over time.

It’s up to you to choose whether to allow your data to be used to improve new Claude models and you can change your choice anytime in your [Privacy Settings](https://claude.ai/settings/data-privacy-controls).

#### Why are you extending the data retention period?

AI development cycles span years—models released today began development 18 to 24 months ago. Keeping data consistent across the training process helps make the models more consistent, too: models trained on similar data will respond, reason, and produce outputs in similar ways, making the changes between model upgrades much smoother for users.

The extended retention period also helps us improve our classifiers—systems that help us identify misuse—to detect harmful usage patterns. These systems get better at identifying activity like abuse, spam, or misuse when they can learn from data collected over longer periods, helping us keep Claude safe for everyone.

If you change your setting on providing your data for training or delete your account, we'll exclude your data from future model training. If you delete individual chats, they won't be included in future training either. Learn more about our data retention practices [here](https://privacy.anthropic.com/en/articles/10023548-how-long-do-you-store-my-data).

#### What action do I need to take?

Current users will see an in-app notification asking whether you want to share your chats and coding sessions for model improvement. You can make your selection right away, or select "not now" and decide later. You have until October 8, 2025 to make your choice. If you choose this option, the updated 5-year data retention policy will also immediately apply to new and resumed chats and coding sessions. Once October 8 arrives, you'll need to select your preference to continue using Claude.

If you're signing up for Claude today, you'll see this decision as part of the signup flow. And remember—you can always update your preference in Privacy Settings.

#### What happens if I allow my data to be used for model training and then change my mind?

You can always update your selection in your Privacy Settings. If you decide to turn off the model training setting, we will not use any new chats and coding sessions you have with Claude for future model training. Your data will still be included in model training that has already started and in models that have already been trained, but we will stop using your previously stored chats and coding sessions in future model training runs.


<!-- Content filtered: site navigation/footer -->
