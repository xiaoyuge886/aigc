---
source_url: https://platform.claude.com/docs/en/api/go/messages/batches/results
source_type: sitemap
content_hash: sha256:498f7c68dd0e5c97a13abde727880c18023f83ff3444207806aa77bfe4bb03a7
sitemap_url: https://platform.claude.com/sitemap.xml
fetch_method: markdown
---

## Results

`client.Messages.Batches.Results(ctx, messageBatchID) (*MessageBatchIndividualResponse, error)`

**get** `/v1/messages/batches/{message_batch_id}/results`

Streams the results of a Message Batch as a `.jsonl` file.

Each line in the file is a JSON object containing the result of a single request in the Message Batch. Results are not guaranteed to be in the same order as requests. Use the `custom_id` field to match results to requests.

Learn more about the Message Batches API in our [user guide](https://docs.claude.com/en/docs/build-with-claude/batch-processing)

### Parameters

- `messageBatchID string`

  ID of the Message Batch.

### Returns

- `type MessageBatchIndividualResponse struct{…}`

  This is a single line in the response `.jsonl` file and does not represent the response as a whole.

  - `CustomID string`

    Developer-provided ID created for each request in a Message Batch. Useful for matching results to requests, as results may be given out of request order.

    Must be unique for each request within the Message Batch.

  - `Result MessageBatchResultUnion`

    Processing result for this request.

    Contains a Message output if processing was successful, an error response if processing failed, or the reason why processing was not attempted, such as cancellation or expiration.

    - `type MessageBatchSucceededResult struct{…}`

      - `Message Message`

        - `ID string`

          Unique object identifier.

          The format and length of IDs may change over time.

        - `Content []ContentBlockUnion`

          Content generated by the model.

          This is an array of content blocks, each of which has a `type` that determines its shape.

          Example:

          ```json
          [{"type": "text", "text": "Hi, I'm Claude."}]
          ```

          If the request input `messages` ended with an `assistant` turn, then the response `content` will continue directly from that last turn. You can use this to constrain the model's output.

          For example, if the input `messages` were:

          ```json
          [
            {"role": "user", "content": "What's the Greek name for Sun? (A) Sol (B) Helios (C) Sun"},
            {"role": "assistant", "content": "The best answer is ("}
          ]
          ```

          Then the response `content` might be:

          ```json
          [{"type": "text", "text": "B)"}]
          ```

          - `type TextBlock struct{…}`

            - `Citations []TextCitationUnion`

              Citations supporting the text block.

              The type of citation returned will depend on the type of document being cited. Citing a PDF results in `page_location`, plain text results in `char_location`, and content document results in `content_block_location`.

              - `type CitationCharLocation struct{…}`

                - `CitedText string`

                - `DocumentIndex int64`

                - `DocumentTitle string`

                - `EndCharIndex int64`

                - `FileID string`

                - `StartCharIndex int64`

                - `Type CharLocation`

                  - `const CharLocationCharLocation CharLocation = "char_location"`

              - `type CitationPageLocation struct{…}`

                - `CitedText string`

                - `DocumentIndex int64`

                - `DocumentTitle string`

                - `EndPageNumber int64`

                - `FileID string`

                - `StartPageNumber int64`

                - `Type PageLocation`

                  - `const PageLocationPageLocation PageLocation = "page_location"`

              - `type CitationContentBlockLocation struct{…}`

                - `CitedText string`

                - `DocumentIndex int64`

                - `DocumentTitle string`

                - `EndBlockIndex int64`

                - `FileID string`

                - `StartBlockIndex int64`

                - `Type ContentBlockLocation`

                  - `const ContentBlockLocationContentBlockLocation ContentBlockLocation = "content_block_location"`

              - `type CitationsWebSearchResultLocation struct{…}`

                - `CitedText string`

                - `EncryptedIndex string`

                - `Title string`

                - `Type WebSearchResultLocation`

                  - `const WebSearchResultLocationWebSearchResultLocation WebSearchResultLocation = "web_search_result_location"`

                - `URL string`

              - `type CitationsSearchResultLocation struct{…}`

                - `CitedText string`

                - `EndBlockIndex int64`

                - `SearchResultIndex int64`

                - `Source string`

                - `StartBlockIndex int64`

                - `Title string`

                - `Type SearchResultLocation`

                  - `const SearchResultLocationSearchResultLocation SearchResultLocation = "search_result_location"`

            - `Text string`

            - `Type Text`

              - `const TextText Text = "text"`

          - `type ThinkingBlock struct{…}`

            - `Signature string`

            - `Thinking string`

            - `Type Thinking`

              - `const ThinkingThinking Thinking = "thinking"`

          - `type RedactedThinkingBlock struct{…}`

            - `Data string`

            - `Type RedactedThinking`

              - `const RedactedThinkingRedactedThinking RedactedThinking = "redacted_thinking"`

          - `type ToolUseBlock struct{…}`

            - `ID string`

            - `Input map[string, any]`

            - `Name string`

            - `Type ToolUse`

              - `const ToolUseToolUse ToolUse = "tool_use"`

          - `type ServerToolUseBlock struct{…}`

            - `ID string`

            - `Input map[string, any]`

            - `Name WebSearch`

              - `const WebSearchWebSearch WebSearch = "web_search"`

            - `Type ServerToolUse`

              - `const ServerToolUseServerToolUse ServerToolUse = "server_tool_use"`

          - `type WebSearchToolResultBlock struct{…}`

            - `Content WebSearchToolResultBlockContentUnion`

              - `type WebSearchToolResultError struct{…}`

                - `ErrorCode WebSearchToolResultErrorErrorCode`

                  - `const WebSearchToolResultErrorErrorCodeInvalidToolInput WebSearchToolResultErrorErrorCode = "invalid_tool_input"`

                  - `const WebSearchToolResultErrorErrorCodeUnavailable WebSearchToolResultErrorErrorCode = "unavailable"`

                  - `const WebSearchToolResultErrorErrorCodeMaxUsesExceeded WebSearchToolResultErrorErrorCode = "max_uses_exceeded"`

                  - `const WebSearchToolResultErrorErrorCodeTooManyRequests WebSearchToolResultErrorErrorCode = "too_many_requests"`

                  - `const WebSearchToolResultErrorErrorCodeQueryTooLong WebSearchToolResultErrorErrorCode = "query_too_long"`

                - `Type WebSearchToolResultError`

                  - `const WebSearchToolResultErrorWebSearchToolResultError WebSearchToolResultError = "web_search_tool_result_error"`

              - `type WebSearchToolResultBlockContentArray []WebSearchResultBlock`

                - `EncryptedContent string`

                - `PageAge string`

                - `Title string`

                - `Type WebSearchResult`

                  - `const WebSearchResultWebSearchResult WebSearchResult = "web_search_result"`

                - `URL string`

            - `ToolUseID string`

            - `Type WebSearchToolResult`

              - `const WebSearchToolResultWebSearchToolResult WebSearchToolResult = "web_search_tool_result"`

        - `Model Model`

          The model that will complete your prompt.

          See [models](https://docs.anthropic.com/en/docs/models-overview) for additional details and options.

          - `type Model string`

            The model that will complete your prompt.

            See [models](https://docs.anthropic.com/en/docs/models-overview) for additional details and options.

            - `const ModelClaudeOpus4_5_20251101 Model = "claude-opus-4-5-20251101"`

              Premium model combining maximum intelligence with practical performance

            - `const ModelClaudeOpus4_5 Model = "claude-opus-4-5"`

              Premium model combining maximum intelligence with practical performance

            - `const ModelClaude3_7SonnetLatest Model = "claude-3-7-sonnet-latest"`

              High-performance model with early extended thinking

            - `const ModelClaude3_7Sonnet20250219 Model = "claude-3-7-sonnet-20250219"`

              High-performance model with early extended thinking

            - `const ModelClaude3_5HaikuLatest Model = "claude-3-5-haiku-latest"`

              Fastest and most compact model for near-instant responsiveness

            - `const ModelClaude3_5Haiku20241022 Model = "claude-3-5-haiku-20241022"`

              Our fastest model

            - `const ModelClaudeHaiku4_5 Model = "claude-haiku-4-5"`

              Hybrid model, capable of near-instant responses and extended thinking

            - `const ModelClaudeHaiku4_5_20251001 Model = "claude-haiku-4-5-20251001"`

              Hybrid model, capable of near-instant responses and extended thinking

            - `const ModelClaudeSonnet4_20250514 Model = "claude-sonnet-4-20250514"`

              High-performance model with extended thinking

            - `const ModelClaudeSonnet4_0 Model = "claude-sonnet-4-0"`

              High-performance model with extended thinking

            - `const ModelClaude4Sonnet20250514 Model = "claude-4-sonnet-20250514"`

              High-performance model with extended thinking

            - `const ModelClaudeSonnet4_5 Model = "claude-sonnet-4-5"`

              Our best model for real-world agents and coding

            - `const ModelClaudeSonnet4_5_20250929 Model = "claude-sonnet-4-5-20250929"`

              Our best model for real-world agents and coding

            - `const ModelClaudeOpus4_0 Model = "claude-opus-4-0"`

              Our most capable model

            - `const ModelClaudeOpus4_20250514 Model = "claude-opus-4-20250514"`

              Our most capable model

            - `const ModelClaude4Opus20250514 Model = "claude-4-opus-20250514"`

              Our most capable model

            - `const ModelClaudeOpus4_1_20250805 Model = "claude-opus-4-1-20250805"`

              Our most capable model

            - `const ModelClaude3OpusLatest Model = "claude-3-opus-latest"`

              Excels at writing and complex tasks

            - `const ModelClaude_3_Opus_20240229 Model = "claude-3-opus-20240229"`

              Excels at writing and complex tasks

            - `const ModelClaude_3_Haiku_20240307 Model = "claude-3-haiku-20240307"`

              Our previous most fast and cost-effective

          - `string`

        - `Role Assistant`

          Conversational role of the generated message.

          This will always be `"assistant"`.

          - `const AssistantAssistant Assistant = "assistant"`

        - `StopReason StopReason`

          The reason that we stopped.

          This may be one the following values:

          * `"end_turn"`: the model reached a natural stopping point
          * `"max_tokens"`: we exceeded the requested `max_tokens` or the model's maximum
          * `"stop_sequence"`: one of your provided custom `stop_sequences` was generated
          * `"tool_use"`: the model invoked one or more tools
          * `"pause_turn"`: we paused a long-running turn. You may provide the response back as-is in a subsequent request to let the model continue.
          * `"refusal"`: when streaming classifiers intervene to handle potential policy violations

          In non-streaming mode this value is always non-null. In streaming mode, it is null in the `message_start` event and non-null otherwise.

          - `const StopReasonEndTurn StopReason = "end_turn"`

          - `const StopReasonMaxTokens StopReason = "max_tokens"`

          - `const StopReasonStopSequence StopReason = "stop_sequence"`

          - `const StopReasonToolUse StopReason = "tool_use"`

          - `const StopReasonPauseTurn StopReason = "pause_turn"`

          - `const StopReasonRefusal StopReason = "refusal"`

        - `StopSequence string`

          Which custom stop sequence was generated, if any.

          This value will be a non-null string if one of your custom stop sequences was generated.

        - `Type Message`

          Object type.

          For Messages, this is always `"message"`.

          - `const MessageMessage Message = "message"`

        - `Usage Usage`

          Billing and rate-limit usage.

          Anthropic's API bills and rate-limits by token counts, as tokens represent the underlying cost to our systems.

          Under the hood, the API transforms requests into a format suitable for the model. The model's output then goes through a parsing stage before becoming an API response. As a result, the token counts in `usage` will not match one-to-one with the exact visible content of an API request or response.

          For example, `output_tokens` will be non-zero, even for an empty string response from Claude.

          Total input tokens in a request is the summation of `input_tokens`, `cache_creation_input_tokens`, and `cache_read_input_tokens`.

          - `CacheCreation CacheCreation`

            Breakdown of cached tokens by TTL

            - `Ephemeral1hInputTokens int64`

              The number of input tokens used to create the 1 hour cache entry.

            - `Ephemeral5mInputTokens int64`

              The number of input tokens used to create the 5 minute cache entry.

          - `CacheCreationInputTokens int64`

            The number of input tokens used to create the cache entry.

          - `CacheReadInputTokens int64`

            The number of input tokens read from the cache.

          - `InputTokens int64`

            The number of input tokens which were used.

          - `OutputTokens int64`

            The number of output tokens which were used.

          - `ServerToolUse ServerToolUsage`

            The number of server tool requests.

            - `WebSearchRequests int64`

              The number of web search tool requests.

          - `ServiceTier UsageServiceTier`

            If the request used the priority, standard, or batch tier.

            - `const UsageServiceTierStandard UsageServiceTier = "standard"`

            - `const UsageServiceTierPriority UsageServiceTier = "priority"`

            - `const UsageServiceTierBatch UsageServiceTier = "batch"`

      - `Type Succeeded`

        - `const SucceededSucceeded Succeeded = "succeeded"`

    - `type MessageBatchErroredResult struct{…}`

      - `Error ErrorResponse`

        - `Error ErrorObjectUnion`

          - `type InvalidRequestError struct{…}`

            - `Message string`

            - `Type InvalidRequestError`

              - `const InvalidRequestErrorInvalidRequestError InvalidRequestError = "invalid_request_error"`

          - `type AuthenticationError struct{…}`

            - `Message string`

            - `Type AuthenticationError`

              - `const AuthenticationErrorAuthenticationError AuthenticationError = "authentication_error"`

          - `type BillingError struct{…}`

            - `Message string`

            - `Type BillingError`

              - `const BillingErrorBillingError BillingError = "billing_error"`

          - `type PermissionError struct{…}`

            - `Message string`

            - `Type PermissionError`

              - `const PermissionErrorPermissionError PermissionError = "permission_error"`

          - `type NotFoundError struct{…}`

            - `Message string`

            - `Type NotFoundError`

              - `const NotFoundErrorNotFoundError NotFoundError = "not_found_error"`

          - `type RateLimitError struct{…}`

            - `Message string`

            - `Type RateLimitError`

              - `const RateLimitErrorRateLimitError RateLimitError = "rate_limit_error"`

          - `type GatewayTimeoutError struct{…}`

            - `Message string`

            - `Type TimeoutError`

              - `const TimeoutErrorTimeoutError TimeoutError = "timeout_error"`

          - `type APIErrorObject struct{…}`

            - `Message string`

            - `Type APIError`

              - `const APIErrorAPIError APIError = "api_error"`

          - `type OverloadedError struct{…}`

            - `Message string`

            - `Type OverloadedError`

              - `const OverloadedErrorOverloadedError OverloadedError = "overloaded_error"`

        - `RequestID string`

        - `Type Error`

          - `const ErrorError Error = "error"`

      - `Type Errored`

        - `const ErroredErrored Errored = "errored"`

    - `type MessageBatchCanceledResult struct{…}`

      - `Type Canceled`

        - `const CanceledCanceled Canceled = "canceled"`

    - `type MessageBatchExpiredResult struct{…}`

      - `Type Expired`

        - `const ExpiredExpired Expired = "expired"`

### Example

```go
package main

import (
  "context"
  "fmt"

  "github.com/anthropics/anthropic-sdk-go"
  "github.com/anthropics/anthropic-sdk-go/option"
)

func main() {
  client := anthropic.NewClient(
    option.WithAPIKey("my-anthropic-api-key"),
  )
  stream := client.Messages.Batches.ResultsStreaming(context.TODO(), "message_batch_id")
  if stream.Err() != nil {
    panic(err.Error())
  }
  fmt.Printf("%+v\n", messageBatchIndividualResponse.CustomID)
}
```
