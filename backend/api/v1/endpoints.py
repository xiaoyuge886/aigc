"""
FastAPI routes for Agent API
"""
import asyncio
import json
import re
from typing import AsyncIterator, Optional, Dict, List, Dict, List

from fastapi import APIRouter, Depends, HTTPException, status
from fastapi.responses import StreamingResponse
from loguru import logger
from datetime import datetime


def format_utc_timestamp(dt: datetime) -> str:
    """
    æ ¼å¼åŒ– UTC æ—¶é—´æˆ³ï¼Œç¡®ä¿åŒ…å«æ—¶åŒºä¿¡æ¯
    
    æ•°æ®åº“å­˜å‚¨çš„æ˜¯ UTC æ—¶é—´ï¼ˆä½¿ç”¨ datetime.utcnow()ï¼‰ï¼Œ
    ä½† naive datetime çš„ isoformat() ä¸åŒ…å«æ—¶åŒºæ ‡è®°ã€‚
    å‰ç«¯éœ€è¦æ˜ç¡®çš„æ—¶åŒºä¿¡æ¯æ‰èƒ½æ­£ç¡®è½¬æ¢ä¸ºæœ¬åœ°æ—¶é—´ã€‚
    """
    timestamp_str = dt.isoformat()
    # å¦‚æœæ—¶é—´æˆ³æ²¡æœ‰æ—¶åŒºä¿¡æ¯ï¼ˆnaive datetimeï¼‰ï¼Œæ·»åŠ  'Z' è¡¨ç¤º UTC
    if not timestamp_str.endswith('Z') and '+' not in timestamp_str and timestamp_str.count('-') <= 2:
        timestamp_str = timestamp_str + 'Z'
    return timestamp_str


def clean_message_text(text: str) -> str:
    """
    æ¸…ç†æ¶ˆæ¯æ–‡æœ¬ï¼Œç§»é™¤æœ¬åœ°æ–‡ä»¶è·¯å¾„ç­‰å†…éƒ¨ä¿¡æ¯
    
    æ³¨æ„ï¼šä¿ç•™ URL é“¾æ¥ï¼ˆå¦‚ MinIO é“¾æ¥ï¼‰ï¼Œå› ä¸ºç”¨æˆ·éœ€è¦çœ‹åˆ°å’Œè®¿é—®è¿™äº›é“¾æ¥
    æ–‡ä»¶ä¿¡æ¯ä¹Ÿä¼šé€šè¿‡æ–‡ä»¶äº‹ä»¶å•ç‹¬ä¼ é€’
    """
    if not text:
        return text
    
    cleaned = text
    
    # ç§»é™¤æœ¬åœ°æ–‡ä»¶è·¯å¾„ï¼ˆwork_dir/reports/...ï¼‰
    # ä½†ä¿ç•™ URL é“¾æ¥ï¼Œå› ä¸ºç”¨æˆ·éœ€è¦è®¿é—®è¿™äº›é“¾æ¥
    cleaned = re.sub(r'work_dir/reports/[^\s\n\)\]]+\.[a-zA-Z0-9]+', '', cleaned)

    # æ³¨é‡Šæ‰çš„æ¸…ç†è§„åˆ™å·²ç§»é™¤ï¼Œä¿ç•™æ‰€æœ‰ç”¨æˆ·ç”Ÿæˆçš„å†…å®¹
    # åŒ…æ‹¬æœ¬åœ°æ–‡ä»¶è·¯å¾„å’Œ MinIO URLï¼ˆç”¨æˆ·éœ€è¦è®¿é—®è¿™äº›é“¾æ¥ï¼‰

    # ç§»é™¤åŒ…å«æœ¬åœ°æ–‡ä»¶è·¯å¾„çš„å®Œæ•´è¡Œï¼ˆå¦‚æœæ•´è¡Œåªæœ‰æ–‡ä»¶è·¯å¾„ï¼‰
    # ä½†ä¿ç•™åŒ…å« URL çš„è¡Œï¼Œå› ä¸º URL é€šå¸¸ä¸å…¶ä»–æ–‡æœ¬ä¸€èµ·å‡ºç°
    lines = cleaned.split('\n')
    filtered_lines = []
    for line in lines:
        trimmed = line.strip()
        # è·³è¿‡ç©ºè¡Œ
        if not trimmed:
            filtered_lines.append(line)
            continue
        # åªè¿‡æ»¤æ‰åªåŒ…å«æœ¬åœ°æ–‡ä»¶è·¯å¾„çš„è¡Œï¼ˆä¸åŒ…å« URLï¼‰
        if re.match(r'^work_dir/reports/.+\.(md|txt|html|pdf|docx?|xlsx?|pptx?)$', trimmed, re.IGNORECASE):
            continue
        # ä¿ç•™æ‰€æœ‰å…¶ä»–è¡Œï¼ŒåŒ…æ‹¬ MinIO URL
        filtered_lines.append(line)
    cleaned = '\n'.join(filtered_lines)
    
    # ç§»é™¤å¤šä½™çš„ç©ºè¡Œ
    cleaned = re.sub(r'\n{3,}', '\n\n', cleaned)
    
    return cleaned.strip()

from services.agent_service import get_agent_service, AgentService
from services.session_manager import get_session_manager, SessionManager
from models.schemas import (
    AgentRequest,
    AgentResponse,
    AssistantMessage,
    ContentBlock,
    ErrorResponse,
    ResultInfo,
    SessionCreateRequest,
    SessionResponse,
    StreamChunk,
    SystemMessage,
    UserMessage,
    ConversationHistoryResponse,
    HistoryMessage,
    MessageResultInfo,
    ToolCallInfo,
    FrontendLogRequest,
    FrontendLogResponse,
    FileEventInfo,
    DataFlowNode,
    DataFlowResponse,
)
from services.database import get_database_service, DatabaseService
from sqlalchemy import select
from models.database import UserScenarioConfigDB, MessageDB
from services.configuration_manager import ConfigurationManager
from services.file_upload_service import FileUploadService
from services.prompt_composer import PromptComposer
from services.file_reference_parser import FileReferenceParser
from services.file_intent_detector import FileIntentDetector
from services.file_search_service import FileSearchService
from services.file_content_loader import FileContentLoader
from services.feedback_collector import FeedbackCollector
from api.v1.auth import get_current_user_optional
from models.database import UserDB


router = APIRouter(tags=["agent"])


@router.post("/agent/query", response_model=AgentResponse)
async def query_agent(
    request: AgentRequest,
    agent_service: AgentService = Depends(get_agent_service)
):
    """
    Execute a single stateless query (creates new session each time)

    This uses query_once() which creates a fresh Claude session for each request.
    No conversation context is preserved between calls.

    Best for:
        - Simple one-off questions
        - Batch processing of independent prompts
        - Code generation or analysis tasks
        - Automated scripts

    For multi-turn conversations, use /session endpoints instead.
    """
    try:
        messages = []
        result = None

        async for msg in agent_service.query_once(
            prompt=request.prompt,
            system_prompt=request.system_prompt,
            allowed_tools=request.allowed_tools,
            model=request.model,
        ):
            if isinstance(msg, (AssistantMessage, SystemMessage)):
                messages.append(msg)
            elif isinstance(msg, ResultInfo):
                result = msg

        return AgentResponse(
            session_id="single",
            messages=messages,
            result=result
        )

    except Exception as e:
        logger.error(f"Error in query_agent: {e}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=str(e)
        )


@router.post("/agent/query/stream")
async def query_agent_stream(
    request: AgentRequest,
    agent_service: AgentService = Depends(get_agent_service)
):
    """
    Execute a streaming stateless query

    This uses query_once() with Server-Sent Events (SSE) for real-time responses.
    Each request creates a fresh session with no conversation context.

    Best for:
        - Real-time responses to one-off questions
        - Simple queries where you want to see Claude thinking
        - Batch processing with streaming output

    For multi-turn conversations, use /session/query/stream instead.

    Incremental Streaming:
        Set `incremental_stream=true` in request to enable text-level streaming.
        This sends each text fragment as it arrives (character-by-character or word-by-word).
    """
    async def event_generator() -> AsyncIterator[str]:
        try:
            async for msg in agent_service.query_once(
                prompt=request.prompt,
                system_prompt=request.system_prompt,
                allowed_tools=request.allowed_tools,
                model=request.model,
                include_partial_messages=request.incremental_stream,
            ):
                # å¤„ç†å¢é‡æµå¼æ–‡æœ¬ç‰‡æ®µ
                if isinstance(msg, ContentBlock) and msg.type == "text_delta":
                    chunk = StreamChunk(type="text_delta", data=msg)
                    yield f"data: {chunk.model_dump_json()}\n\n"
                else:
                    chunk = StreamChunk(type="data", data=msg)
                    yield f"data: {chunk.model_dump_json()}\n\n"

        except Exception as e:
            logger.error(f"Error in query_agent_stream: {e}")
            error_chunk = StreamChunk(
                type="error",
                data=ErrorResponse(error=str(e))
            )
            yield f"data: {error_chunk.model_dump_json()}\n\n"

    return StreamingResponse(
        event_generator(),
        media_type="text/event-stream",
        headers={
            "Cache-Control": "no-cache",
            "Connection": "keep-alive",
        }
    )


@router.post("/session", response_model=SessionResponse)
async def create_session(
    request: SessionCreateRequest,
    agent_service: AgentService = Depends(get_agent_service),
    session_mgr: SessionManager = Depends(get_session_manager),
    current_user: Optional[UserDB] = Depends(get_current_user_optional),
    db_service: DatabaseService = Depends(get_database_service),
):
    """
    Create a new agent session for multi-turn conversations

    This endpoint is optional. You can also start a conversation directly
    by calling POST /session/query or POST /session/query/stream with
    session_id=null.

    If you use this endpoint:
    1. Creates a session with specific configuration
    2. Returns a session_id for subsequent queries
    3. Use the session_id in POST /session/query or /session/query/stream

    The session_id can be used for subsequent queries via:
        - POST /session/query (with session_id in request body)
        - POST /session/query/stream (with session_id in request body)

    Incremental Streaming:
        Set `incremental_stream=true` to enable text-level streaming for
        all queries in this session. This setting cannot be changed after
        session creation.

    Authentication (Optional):
        - If JWT token provided: session is bound to the authenticated user
        - If no token: session is created as anonymous (user_id=None)

    Platform Configuration (Optional):
        - If user has custom configuration, it will be applied
        - Request-level parameters override user configuration
        - Configuration priority: Request > Session > User > Global

    Returns:
        SessionResponse with session_id and creation timestamp
    """
    try:
        # è·å–ç”¨æˆ· IDï¼ˆå¦‚æœæœ‰è®¤è¯ç”¨æˆ·ï¼‰
        user_id = current_user.id if current_user else None
        if current_user:
            logger.info(f"Creating session for authenticated user: {current_user.username}")
        else:
            logger.info("Creating anonymous session (no authentication)")

        # Platform configuration (optional, doesn't affect core logic)
        agent_config = None
        if user_id:
            try:
                config_manager = ConfigurationManager(db_service)
                user_config = await config_manager.get_user_config(user_id)
                
                # Build request config from request parameters
                request_config = {}
                if request.system_prompt:
                    request_config["system_prompt"] = request.system_prompt
                if request.allowed_tools:
                    request_config["allowed_tools"] = request.allowed_tools
                if request.model:
                    request_config["model"] = request.model
                
                # Build session config (from request, will be saved to session)
                session_config = request_config.copy()
                
                # Merge configurations
                agent_config, _ = config_manager.merge_agent_config(
                    request_config=request_config,
                    session_config=session_config,
                    user_config=user_config,
                )
                logger.debug(f"Applied platform configuration for user_id={user_id}")
            except Exception as e:
                logger.warning(f"Failed to load platform configuration for user_id={user_id}: {e}")
                # Continue with default configuration (backward compatible)

        # Create options (with platform config if available)
        options = agent_service.create_options(
            system_prompt=request.system_prompt,
            allowed_tools=request.allowed_tools,
            model=request.model,
            include_partial_messages=request.incremental_stream,
            agent_config=agent_config,  # Platform configuration (optional)
        )

        session = await session_mgr.create_session(
            options=options,
            user_id=user_id  # â† ç»‘å®šåˆ°ç”¨æˆ·
        )

        return SessionResponse(
            session_id=session.session_id,
            created_at=format_utc_timestamp(session.created_at)
        )

    except Exception as e:
        logger.error(f"Error creating session: {e}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=str(e)
        )


@router.post("/session/query", response_model=AgentResponse)
async def session_query(
    request: AgentRequest,
    agent_service: AgentService = Depends(get_agent_service),
):
    """
    Send a query in a session (supports both new and existing sessions)

    This uses query_in_session() for multi-turn conversations.
    Claude will remember the conversation context from previous queries
    in the same session.

    Args:
        request: AgentRequest with:
            - prompt: User prompt to send to Claude
            - session_id: Optional session identifier (None for first query in new session)
            - Other optional parameters (system_prompt, allowed_tools, model, etc.)

    Returns:
        AgentResponse with messages and result metadata

    Session Handling:
        - First query: Send session_id=null or omit it to create a new conversation
        - Subsequent queries: Send the session_id returned in the ResultMessage
          to continue the conversation
    """
    try:
        # Get session_id from request body (can be None for first query)
        session_id = request.session_id

        messages = []
        result = None

        async for msg in agent_service.query_in_session(
            prompt=request.prompt,
            session_id=session_id or "",  # Empty string for first query
            include_partial_messages=request.incremental_stream  # ä¼ é€’å¢é‡æµå¼å‚æ•°
            # åŒ¿åç”¨æˆ·ä¸ä¼  user_idï¼Œä½¿ç”¨é»˜è®¤ work_dir
        ):
            if isinstance(msg, (AssistantMessage, SystemMessage)):
                messages.append(msg)
            elif isinstance(msg, ResultInfo):
                result = msg

        return AgentResponse(
            session_id=session_id or "new",
            messages=messages,
            result=result
        )

    except Exception as e:
        logger.error(f"Error in session_query: {e}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=str(e)
        )


@router.post("/session/query/stream")
async def session_query_stream(
    request: AgentRequest,
    agent_service: AgentService = Depends(get_agent_service),
    session_mgr: SessionManager = Depends(get_session_manager),
    db_service: DatabaseService = Depends(get_database_service),
    current_user: Optional[UserDB] = Depends(get_current_user_optional),
):
    """
    core å†ç”¨
    Send a streaming query in a session (supports both new and existing sessions)

    This uses query_in_session() with Server-Sent Events (SSE) for real-time
    responses in a multi-turn conversation. Claude maintains context from
    previous messages in the session.

    Args:
        request: AgentRequest with:
            - prompt: User prompt to send to Claude
            - session_id: Optional session identifier (None for first query in new session)
            - Other optional parameters (system_prompt, allowed_tools, model, etc.)

    Returns:
        Server-Sent Events stream with real-time messages

    Session Handling:
        - First query: Send session_id=null or omit it to create a new conversation
        - Subsequent queries: Send the session_id returned in the ResultMessage
          to continue the conversation

    Incremental Streaming:
        If the session was created with `incremental_stream=true`, text deltas
        will be sent as type="text_delta" chunks for character-level streaming.

    Example:
        ```python
        # First query (create new session)
        async with httpx.AsyncClient() as client:
            async with client.stream(
                "POST",
                "/api/v1/session/query/stream",
                json={"prompt": "Hello", "session_id": None}
            ) as response:
                async for line in response.aiter_lines():
                    if line.startswith("data: "):
                        data = json.loads(line[6:])
                        # Extract session_id from ResultMessage for next query

        # Second query (continue conversation)
        async with client.stream(
            "POST",
            "/api/v1/session/query/stream",
            json={"prompt": "How are you?", "session_id": "<previous_session_id>"}
        ) as response:
            async for line in response.aiter_lines():
                if line.startswith("data: "):
                    data = json.loads(line[6:])
                    # Process data
        ```
    """
    async def event_generator() -> AsyncIterator[str]:
        import uuid
        
        session_id = None
        user_message_saved = False
        user_message_id = None  # ä¿å­˜ç”¨æˆ·æ¶ˆæ¯çš„IDï¼Œç”¨äºè®¾ç½®parent_message_id
        assistant_message_id = None  # ä¿å­˜AIæ¶ˆæ¯çš„IDï¼Œç”¨äºè®¾ç½®tool_useçš„parent_message_id
        conversation_turn_id = None  # åŒä¸€è½®å¯¹è¯çš„å”¯ä¸€ID
        session_created = False  # æ ‡è®°ä¼šè¯æ˜¯å¦å·²åˆ›å»º
        assistant_content = []  # æ”¶é›† AssistantMessage çš„å†…å®¹
        tool_calls = []  # æ”¶é›†å·¥å…·è°ƒç”¨ä¿¡æ¯
        saved_tool_use_ids = set()  # è¿½è¸ªå·²ä¿å­˜çš„ tool_use_idï¼Œç¡®ä¿åŒä¸€IDåªä¿å­˜ä¸€æ¬¡
        result_info_dict = None  # ä¿å­˜ ResultMessage ä¿¡æ¯
        tool_use_index_map = {}  # ğŸ”§ ç»´æŠ¤ index -> tool_use_id çš„æ˜ å°„ï¼Œç”¨äº tool_input_delta äº‹ä»¶
        pending_tool_input_deltas: Dict[int, List[ContentBlock]] = {}  # ğŸ”§ ç¼“å­˜å¾…å¤„ç†çš„ tool_input_delta äº‹ä»¶ï¼Œkey æ˜¯ indexï¼Œvalue æ˜¯ ContentBlock åˆ—è¡¨
        
        try:
            # Get session_id from request body (can be None for first query)
            session_id = request.session_id
            logger.info(f"[session_query_stream] Starting query for session {session_id or 'new session'}")
            logger.info(f"[session_query_stream] incremental_stream={request.incremental_stream}")

            # ==================== æå‰ç”Ÿæˆ conversation_turn_id ====================
            # conversation_turn_id åœ¨è¯·æ±‚å¼€å§‹æ—¶ç«‹å³ç”Ÿæˆï¼Œä¸ä¾èµ–ä»»ä½•å¤–éƒ¨æœåŠ¡
            # è¿™æ ·å¯ä»¥ç¡®ä¿æ–‡ä»¶ä¸Šä¼ æ—¶å°±æœ‰å¯ç”¨çš„ conversation_turn_id
            conversation_turn_id = uuid.uuid4().hex[:16]
            logger.info(f"[session_query_stream] âœ… Generated conversation_turn_id: {conversation_turn_id} (early generation)")
            
            # ä¿å­˜ç”¨æˆ·æ¶ˆæ¯ï¼ˆå¦‚æœå·²æœ‰ session_idï¼‰
            if session_id:
                user_message_id = await session_mgr.save_message(
                    session_id=session_id,
                    role="user",
                    message_type="text",
                    content=request.prompt,
                    conversation_turn_id=conversation_turn_id,
                )
                user_message_saved = True

            # Load user configuration BEFORE creating the agent client
            # This ensures the correct system_prompt is used from the start
            agent_config = None
            if current_user:
                try:
                    config_manager = ConfigurationManager(db_service)
                    user_config = await config_manager.get_user_config(current_user.id)
                    
                    logger.info(f"[session_query_stream] Loading config for user_id={current_user.id}, username={current_user.username} (BEFORE query)")
                    logger.info(f"[session_query_stream] User config found: {user_config is not None}")
                    if user_config:
                        logger.info(f"[session_query_stream] User config - system_prompt: {user_config.default_system_prompt[:100] if user_config.default_system_prompt else None}...")
                    
                    # Build request config from request parameters
                    request_config = {}
                    if request.system_prompt:
                        request_config["system_prompt"] = request.system_prompt
                        logger.info(f"[session_query_stream] Request has system_prompt (will override user config)")
                    if request.allowed_tools:
                        request_config["allowed_tools"] = request.allowed_tools
                    if request.model:
                        request_config["model"] = request.model
                    
                    # Build session config
                    session_config = request_config.copy()
                    
                    # Load scenario config if user has associated scenario
                    # ä¼˜å…ˆçº§ï¼šè¯·æ±‚å‚æ•° > ç”¨æˆ·åœºæ™¯é…ç½®ï¼ˆUserScenarioConfigDBï¼‰ > ç”¨æˆ·é…ç½®å…³è”çš„åœºæ™¯ï¼ˆUserConfigDBï¼Œå‘åå…¼å®¹ï¼‰
                    scenario_config = None
                    scenario_id = None
                    user_id = current_user.id if current_user else None
                    
                    # æ–¹æ¡ˆ1ï¼šä»è¯·æ±‚å‚æ•°ä¸­è·å– scenario_idï¼ˆå¦‚æœå‰ç«¯ä¼ é€’ï¼Œä¼˜å…ˆçº§æœ€é«˜ï¼‰
                    if hasattr(request, 'scenario_id') and request.scenario_id:
                        scenario_id = request.scenario_id
                        logger.info(f"[session_query_stream] Found scenario_id in request: {scenario_id}")
                    
                    # æ–¹æ¡ˆ2ï¼šä»ç”¨æˆ·åœºæ™¯é…ç½®ä¸­è·å–åœºæ™¯åˆ—è¡¨ï¼ˆæ–°æ–¹å¼ï¼Œæ”¯æŒå¤šåœºæ™¯ï¼‰
                    # å¦‚æœç”¨æˆ·é…ç½®äº†å¤šä¸ªåœºæ™¯ï¼Œæ ¹æ®ç”¨æˆ·è¾“å…¥æ™ºèƒ½åŒ¹é…æœ€åˆé€‚çš„åœºæ™¯
                    user_scenario_ids = None
                    if not scenario_id and user_id:
                        try:
                            from models.database import UserScenarioConfigDB
                            async with db_service.async_session() as session:
                                stmt = select(UserScenarioConfigDB).where(
                                    UserScenarioConfigDB.user_id == user_id
                                )
                                result = await session.execute(stmt)
                                user_scenario_config = result.scalar_one_or_none()
                                
                                if user_scenario_config and user_scenario_config.scenario_ids:
                                    try:
                                        scenario_ids = json.loads(user_scenario_config.scenario_ids)
                                        if scenario_ids and len(scenario_ids) > 0:
                                            user_scenario_ids = scenario_ids
                                            logger.info(f"[session_query_stream] Found scenario_ids in UserScenarioConfigDB: {scenario_ids}")
                                            
                                            # å¦‚æœåªæœ‰ä¸€ä¸ªåœºæ™¯ï¼Œç›´æ¥ä½¿ç”¨
                                            if len(scenario_ids) == 1:
                                                scenario_id = scenario_ids[0]
                                                logger.info(f"[session_query_stream] Only one scenario configured, using: {scenario_id}")
                                            # å¦‚æœæœ‰å¤šä¸ªåœºæ™¯ï¼Œä¸”ç”¨æˆ·æä¾›äº†æŸ¥è¯¢å†…å®¹ï¼Œè¿›è¡Œæ™ºèƒ½åŒ¹é…
                                            elif len(scenario_ids) > 1 and request.prompt:
                                                logger.info(f"[session_query_stream] Multiple scenarios configured ({len(scenario_ids)}), will use intelligent matching based on user query")
                                                # åœºæ™¯åŒ¹é…é€»è¾‘å°†åœ¨åé¢æ‰§è¡Œï¼ˆåœ¨ system_prompt is None æ—¶ï¼‰
                                            # å¦‚æœæœ‰å¤šä¸ªåœºæ™¯ä½†æ²¡æœ‰ç”¨æˆ·æŸ¥è¯¢ï¼Œä½¿ç”¨ç¬¬ä¸€ä¸ªï¼ˆå‘åå…¼å®¹ï¼‰
                                            else:
                                                scenario_id = scenario_ids[0]
                                                logger.info(f"[session_query_stream] Multiple scenarios configured but no user query, using first: {scenario_id}")
                                    except json.JSONDecodeError:
                                        logger.warning(f"[session_query_stream] Failed to parse scenario_ids JSON: {user_scenario_config.scenario_ids}")
                        except Exception as e:
                            logger.warning(f"[session_query_stream] Failed to load UserScenarioConfigDB: {e}")
                    
                    # æ–¹æ¡ˆ3ï¼šä»ç”¨æˆ·é…ç½®ä¸­è·å–å…³è”çš„åœºæ™¯ï¼ˆæ—§æ–¹å¼ï¼Œå‘åå…¼å®¹ï¼‰
                    if not scenario_id and user_config and user_config.associated_scenario_id:
                        scenario_id = user_config.associated_scenario_id
                        logger.info(f"[session_query_stream] Found associated_scenario_id in user config (backward compatibility): {scenario_id}")
                    
                    # åŠ è½½åœºæ™¯é…ç½®ï¼ˆå¦‚æœè¿˜æ²¡æœ‰é€šè¿‡æ™ºèƒ½åŒ¹é…åŠ è½½ï¼‰
                    matched_scenario_config = None  # åˆå§‹åŒ–å˜é‡
                    scenario_config = None  # åˆå§‹åŒ–åœºæ™¯é…ç½®å˜é‡
                    
                    # ========== æ™ºèƒ½åœºæ™¯åŒ¹é…ï¼ˆåœ¨ merge_agent_config ä¹‹å‰æ‰§è¡Œï¼‰ ==========
                    # å¦‚æœç”¨æˆ·é…ç½®äº†å¤šä¸ªåœºæ™¯ï¼Œä¸”è¿˜æ²¡æœ‰é€‰æ‹©åœºæ™¯ï¼Œè¿›è¡Œæ™ºèƒ½åŒ¹é…
                    if request.prompt and user_scenario_ids and len(user_scenario_ids) > 1 and not scenario_id:
                        try:
                            from services.scenario_matcher import ScenarioMatcher
                            matcher = ScenarioMatcher(db_service, agent_service)
                            
                            # åªä»ç”¨æˆ·é…ç½®çš„åœºæ™¯åˆ—è¡¨ä¸­è¿›è¡ŒåŒ¹é…
                            logger.info(f"[session_query_stream] ğŸ” å¼€å§‹æ™ºèƒ½åŒ¹é…åœºæ™¯ï¼Œä»ç”¨æˆ·é…ç½®çš„ {len(user_scenario_ids)} ä¸ªåœºæ™¯ä¸­é€‰æ‹©: {user_scenario_ids}")
                            
                            # è·å–è¿™äº›åœºæ™¯çš„è¯¦ç»†ä¿¡æ¯
                            available_scenarios = []
                            for sid in user_scenario_ids:
                                try:
                                    scenario_info = await config_manager.get_business_scenario(sid)
                                    if scenario_info:
                                        available_scenarios.append({
                                            "id": scenario_info.id,  # ä½¿ç”¨æ•´æ•°ID
                                            "name": scenario_info.name,
                                            "description": scenario_info.description or "",
                                            "category": scenario_info.category or "",
                                            "meta": getattr(scenario_info, 'meta', None) or {},
                                            "is_default": getattr(scenario_info, 'is_default', False),
                                        })
                                except Exception as e:
                                    logger.warning(f"[session_query_stream] Failed to load scenario {sid} for matching: {e}")
                            
                            if available_scenarios:
                                # ä½¿ç”¨ ScenarioMatcher çš„æ¨¡å‹åŒ¹é…èƒ½åŠ›ï¼Œä½†åªä»ç”¨æˆ·é…ç½®çš„åœºæ™¯ä¸­é€‰æ‹©
                                matched_scenario = await matcher._match_with_model(
                                    request.prompt,
                                    available_scenarios,
                                    agent_service
                                )
                                
                                if matched_scenario:
                                    scenario_id = matched_scenario.get("id")  # ä½¿ç”¨æ•´æ•°ID
                                    scenario_name = matched_scenario.get("name", "æœªçŸ¥åœºæ™¯")
                                    logger.info(
                                        f"[session_query_stream] âœ… æ™ºèƒ½åŒ¹é…åˆ°åœºæ™¯: "
                                        f"{scenario_name} "
                                        f"(id: {scenario_id})"
                                    )
                                    
                                    # ç«‹å³åŠ è½½åŒ¹é…çš„åœºæ™¯é…ç½®
                                    try:
                                        matched_scenario_config = await config_manager.get_business_scenario(scenario_id)
                                        if matched_scenario_config:
                                            scenario_config = matched_scenario_config  # è®¾ç½®åœºæ™¯é…ç½®
                                            logger.info(
                                                f"[session_query_stream] âœ… å·²åŠ è½½æ™ºèƒ½åŒ¹é…çš„åœºæ™¯é…ç½®: "
                                                f"{matched_scenario_config.name}"
                                            )
                                            # æ‰“å°è¯¦ç»†æŠ¥å‘Š
                                            logger.info("=" * 80)
                                            logger.info("ğŸ“‹ æ™ºèƒ½åœºæ™¯åŒ¹é…è¯¦ç»†æŠ¥å‘Š")
                                            logger.info("=" * 80)
                                            logger.info(f"ğŸ¯ é€‰ä¸­çš„åœºæ™¯åç§°: {matched_scenario_config.name}")
                                            logger.info(f"ğŸ†” åœºæ™¯ID: {matched_scenario_config.id}")
                                            logger.info(f"ğŸ“ åœºæ™¯æè¿°: {matched_scenario_config.description or 'æ— æè¿°'}")
                                            logger.info(f"ğŸ·ï¸  åœºæ™¯åˆ†ç±»: {matched_scenario_config.category or 'æ— åˆ†ç±»'}")
                                            
                                            # æ‰“å°åœºæ™¯çš„ system_prompt
                                            if matched_scenario_config.system_prompt:
                                                prompt_preview = matched_scenario_config.system_prompt[:200] + "..." if len(matched_scenario_config.system_prompt) > 200 else matched_scenario_config.system_prompt
                                                logger.info(f"ğŸ’¬ åœºæ™¯ System Prompt (é•¿åº¦: {len(matched_scenario_config.system_prompt)}):")
                                                logger.info(f"   {prompt_preview}")
                                            else:
                                                logger.info("ğŸ’¬ åœºæ™¯ System Prompt: æ— ")
                                            
                                            # æ‰“å° Skills
                                            if matched_scenario_config.skills:
                                                logger.info(f"ğŸ› ï¸  åœºæ™¯ Skills ({len(matched_scenario_config.skills)}ä¸ª): {matched_scenario_config.skills}")
                                            else:
                                                logger.info("ğŸ› ï¸  åœºæ™¯ Skills: æ— ")
                                            
                                            # æ‰“å° Custom Tools (MCP)
                                            if matched_scenario_config.custom_tools:
                                                logger.info(f"ğŸ”§ åœºæ™¯ Custom Tools (MCP): {matched_scenario_config.custom_tools}")
                                            else:
                                                logger.info("ğŸ”§ åœºæ™¯ Custom Tools (MCP): æ— ")
                                            
                                            # æ‰“å° Allowed Tools
                                            if matched_scenario_config.allowed_tools:
                                                try:
                                                    # allowed_tools æ˜¯ JSON å­—ç¬¦ä¸²ï¼Œéœ€è¦è§£æ
                                                    tools_list = json.loads(matched_scenario_config.allowed_tools) if isinstance(matched_scenario_config.allowed_tools, str) else matched_scenario_config.allowed_tools
                                                    logger.info(f"âœ… åœºæ™¯ Allowed Tools ({len(tools_list)}ä¸ª): {tools_list}")
                                                except (json.JSONDecodeError, TypeError) as e:
                                                    logger.warning(f"âš ï¸  åœºæ™¯ Allowed Tools è§£æå¤±è´¥: {e}, åŸå§‹å€¼: {matched_scenario_config.allowed_tools}")
                                                    logger.info(f"âœ… åœºæ™¯ Allowed Tools (åŸå§‹å€¼): {matched_scenario_config.allowed_tools}")
                                            else:
                                                logger.info("âœ… åœºæ™¯ Allowed Tools: æ— ")
                                            
                                            logger.info("=" * 80)
                                    except Exception as e:
                                        logger.warning(f"[session_query_stream] åŠ è½½æ™ºèƒ½åŒ¹é…åœºæ™¯é…ç½®å¤±è´¥: {e}")
                                else:
                                    # å¦‚æœæ¨¡å‹æ²¡æœ‰åŒ¹é…åˆ°ï¼Œä½¿ç”¨ç¬¬ä¸€ä¸ªåœºæ™¯ï¼ˆé»˜è®¤åœºæ™¯ï¼‰
                                    scenario_id = user_scenario_ids[0]
                                    logger.info(f"[session_query_stream] æ¨¡å‹æœªåŒ¹é…åˆ°åœºæ™¯ï¼Œä½¿ç”¨ç¬¬ä¸€ä¸ªåœºæ™¯: {scenario_id}")
                                    
                                    # åŠ è½½ç¬¬ä¸€ä¸ªåœºæ™¯çš„é…ç½®
                                    try:
                                        matched_scenario_config = await config_manager.get_business_scenario(scenario_id)
                                        if matched_scenario_config:
                                            scenario_config = matched_scenario_config
                                            logger.info(
                                                f"[session_query_stream] âœ… å·²åŠ è½½é»˜è®¤åœºæ™¯é…ç½®: "
                                                f"{matched_scenario_config.name}"
                                            )
                                    except Exception as e:
                                        logger.warning(f"[session_query_stream] åŠ è½½é»˜è®¤åœºæ™¯é…ç½®å¤±è´¥: {e}")
                        except Exception as e:
                            logger.warning(f"[session_query_stream] æ™ºèƒ½åœºæ™¯åŒ¹é…å¤±è´¥: {e}, ä½¿ç”¨ç¬¬ä¸€ä¸ªåœºæ™¯", exc_info=True)
                            if user_scenario_ids:
                                scenario_id = user_scenario_ids[0]
                                # åŠ è½½ç¬¬ä¸€ä¸ªåœºæ™¯çš„é…ç½®
                                try:
                                    matched_scenario_config = await config_manager.get_business_scenario(scenario_id)
                                    if matched_scenario_config:
                                        scenario_config = matched_scenario_config
                                except Exception as e2:
                                    logger.warning(f"[session_query_stream] åŠ è½½é»˜è®¤åœºæ™¯é…ç½®å¤±è´¥: {e2}")
                    
                    # å¦‚æœå·²ç»æœ‰æ˜ç¡®çš„ scenario_idï¼ŒåŠ è½½åœºæ™¯é…ç½®
                    if scenario_id and not scenario_config:
                        try:
                            scenario_config = await config_manager.get_business_scenario(scenario_id)
                            if scenario_config:
                                logger.info(f"[session_query_stream] âœ… Loaded scenario config: id={scenario_config.id}, name={scenario_config.name}")
                                logger.info(f"[session_query_stream] Scenario allowed_tools: {scenario_config.allowed_tools}")
                                logger.info(f"[session_query_stream] Scenario custom_tools: {scenario_config.custom_tools}")
                                logger.info(f"[session_query_stream] Scenario skills: {scenario_config.skills}")
                            else:
                                logger.warning(f"[session_query_stream] Scenario not found: id={scenario_id}")
                        except Exception as e:
                            logger.error(f"[session_query_stream] Failed to load scenario config: {e}", exc_info=True)
                    elif not scenario_id:
                        logger.info(f"[session_query_stream] No scenario_id provided (neither in request nor user config), will try auto-match if user_query provided")
                    
                    # Merge configurationsï¼ˆåœ¨æ™ºèƒ½åŒ¹é…ä¹‹åï¼‰
                    agent_config, config_sources = config_manager.merge_agent_config(
                        request_config=request_config,
                        session_config=session_config,
                        user_config=user_config,
                        scenario_config=scenario_config,  # ä¼ é€’åœºæ™¯é…ç½®ï¼ˆå¯èƒ½æ¥è‡ªæ™ºèƒ½åŒ¹é…ï¼‰
                    )
                    
                    # å¦‚æœ system_prompt ä¸º Noneï¼Œä½¿ç”¨ prompt_composer ç”Ÿæˆé»˜è®¤çš„ system_prompt
                    # æ ¸å¿ƒåŸåˆ™0ï¼šä¸æ”¹å˜ç°æœ‰é—®ç­”é€»è¾‘ï¼Œåªæ˜¯å¢å¼ºé»˜è®¤è¡Œä¸º
                    if agent_config.system_prompt is None:
                        try:
                            prompt_composer = PromptComposer(db_service)
                            
                            # å¦‚æœæ²¡æœ‰é€šè¿‡ç”¨æˆ·é…ç½®åœºæ™¯åŒ¹é…ï¼Œå°è¯•å…¨å±€è‡ªåŠ¨åŒ¹é…
                            if request.prompt and not scenario_config and not scenario_id:
                                try:
                                    from services.scenario_matcher import ScenarioMatcher
                                    matcher = ScenarioMatcher(db_service, agent_service)
                                    matched_scenario = await matcher.match_scenario(
                                        request.prompt, 
                                        user_id,
                                        agent_service=agent_service
                                    )
                                    if matched_scenario:
                                        scenario_id = matched_scenario.get("id")  # ä½¿ç”¨æ•´æ•°ID
                                        scenario_name = matched_scenario.get("name", "æœªçŸ¥åœºæ™¯")
                                        logger.info(
                                            f"[session_query_stream] âœ… è‡ªåŠ¨åŒ¹é…åˆ°åœºæ™¯: "
                                            f"{scenario_name} "
                                            f"(scenario_id: {scenario_id})"
                                        )
                                        
                                        # ç«‹å³åŠ è½½åŒ¹é…çš„åœºæ™¯é…ç½®
                                        try:
                                            matched_scenario_config = await config_manager.get_business_scenario(scenario_id)
                                            if matched_scenario_config:
                                                scenario_config = matched_scenario_config
                                                logger.info(
                                                    f"[session_query_stream] âœ… å·²åŠ è½½åŒ¹é…åœºæ™¯é…ç½®: "
                                                    f"{matched_scenario_config.name}"
                                                )
                                                # é‡æ–°åˆå¹¶é…ç½®
                                                agent_config, config_sources = config_manager.merge_agent_config(
                                                    request_config=request_config,
                                                    session_config=session_config,
                                                    user_config=user_config,
                                                    scenario_config=scenario_config,
                                                )
                                        except Exception as e:
                                            logger.warning(f"[session_query_stream] åŠ è½½åŒ¹é…åœºæ™¯é…ç½®å¤±è´¥: {e}")
                                except Exception as e:
                                    logger.warning(f"[session_query_stream] åœºæ™¯åŒ¹é…å¤±è´¥: {e}")
                            
                            # å¦‚æœåŒ¹é…åˆ°åœºæ™¯å¹¶æˆåŠŸåŠ è½½é…ç½®ï¼Œæ‰“å°è¯¦ç»†æŠ¥å‘Š
                            if scenario_config:
                                # ========== åœºæ™¯åŒ¹é…è¯¦ç»†æŠ¥å‘Š ==========
                                logger.info("=" * 80)
                                logger.info("ğŸ“‹ åœºæ™¯åŒ¹é…è¯¦ç»†æŠ¥å‘Š")
                                logger.info("=" * 80)
                                logger.info(f"ğŸ¯ é€‰ä¸­çš„åœºæ™¯åç§°: {scenario_config.name}")
                                logger.info(f"ğŸ†” åœºæ™¯ID: {scenario_config.id}")
                                logger.info(f"ğŸ“ åœºæ™¯æè¿°: {scenario_config.description or 'æ— æè¿°'}")
                                logger.info(f"ğŸ·ï¸  åœºæ™¯åˆ†ç±»: {scenario_config.category or 'æ— åˆ†ç±»'}")
                                
                                # æ‰“å°åœºæ™¯çš„ system_prompt
                                if scenario_config.system_prompt:
                                    prompt_preview = scenario_config.system_prompt[:200] + "..." if len(scenario_config.system_prompt) > 200 else scenario_config.system_prompt
                                    logger.info(f"ğŸ’¬ åœºæ™¯ System Prompt (é•¿åº¦: {len(scenario_config.system_prompt)}):")
                                    logger.info(f"   {prompt_preview}")
                                else:
                                    logger.info("ğŸ’¬ åœºæ™¯ System Prompt: æ— ")
                                
                                # æ‰“å° Skills
                                if scenario_config.skills:
                                    logger.info(f"ğŸ› ï¸  åœºæ™¯ Skills ({len(scenario_config.skills)}ä¸ª):")
                                    for skill in scenario_config.skills:
                                        logger.info(f"   - {skill}")
                                else:
                                    logger.info("ğŸ› ï¸  åœºæ™¯ Skills: æ— ")
                                
                                # æ‰“å° MCP (custom_tools)
                                if scenario_config.custom_tools:
                                    logger.info(f"ğŸ”Œ åœºæ™¯ MCP Tools (custom_tools):")
                                    tools_str = json.dumps(scenario_config.custom_tools, indent=2, ensure_ascii=False)
                                    # å¦‚æœå¤ªé•¿ï¼Œåªæ˜¾ç¤ºå‰500å­—ç¬¦
                                    if len(tools_str) > 500:
                                        tools_str = tools_str[:500] + "..."
                                    logger.info(f"   {tools_str}")
                                else:
                                    logger.info("ğŸ”Œ åœºæ™¯ MCP Tools: æ— ")
                                
                                # æ‰“å°å…¶ä»–é‡è¦å‚æ•°
                                logger.info("âš™ï¸  å…¶ä»–åœºæ™¯å‚æ•°:")
                                logger.info(f"   - allowed_tools: {scenario_config.allowed_tools or 'æ— '}")
                                logger.info(f"   - recommended_model: {scenario_config.recommended_model or 'æ— '}")
                                logger.info(f"   - permission_mode: {scenario_config.permission_mode or 'æ— '}")
                                logger.info(f"   - max_turns: {scenario_config.max_turns or 'æ— '}")
                                logger.info(f"   - work_dir: {scenario_config.work_dir or 'æ— '}")
                                if scenario_config.workflow:
                                    logger.info(f"   - workflow: {json.dumps(scenario_config.workflow, ensure_ascii=False)[:200]}...")
                                else:
                                    logger.info(f"   - workflow: æ— ")
                                
                                # æ‰“å°åˆå¹¶åçš„é…ç½®æ¥æº
                                logger.info("ğŸ“Š é…ç½®æ¥æº (ä¼˜å…ˆçº§ä»é«˜åˆ°ä½):")
                                for key, source in config_sources.items():
                                    logger.info(f"   - {key}: {source}")
                                
                                # æ‰“å°æœ€ç»ˆåº”ç”¨çš„é…ç½®æ‘˜è¦
                                logger.info("âœ… æœ€ç»ˆåº”ç”¨çš„é…ç½®æ‘˜è¦:")
                                logger.info(f"   - system_prompt é•¿åº¦: {len(agent_config.system_prompt) if agent_config.system_prompt else 0}")
                                logger.info(f"   - allowed_tools: {agent_config.allowed_tools or 'æ— '}")
                                logger.info(f"   - model: {agent_config.model or 'æ— '}")
                                logger.info(f"   - enabled_skill_ids: {agent_config.enabled_skill_ids or 'æ— '}")
                                logger.info(f"   - custom_tools: {'æœ‰' if agent_config.custom_tools else 'æ— '}")
                                logger.info("=" * 80)
                                # ========== åœºæ™¯åŒ¹é…è¯¦ç»†æŠ¥å‘Šç»“æŸ ==========
                            
                            # ç»„åˆ prompt
                            # å¦‚æœå·²ç»åŒ¹é…åˆ°åœºæ™¯å¹¶åŠ è½½äº†é…ç½®ï¼Œåˆ™ä¸å†è‡ªåŠ¨åŒ¹é…ï¼ˆé¿å…é‡å¤ï¼‰
                            auto_match = not scenario_config
                            composed_prompt = await prompt_composer.compose_base_prompt(
                                user_id=user_id,
                                session_id=session_id,
                                user_query=request.prompt if request.prompt else None,
                                auto_match_scenario=auto_match,
                                agent_service=agent_service
                            )
                            if composed_prompt:
                                # å¦‚æœå·²ç»é€šè¿‡åœºæ™¯é…ç½®è®¾ç½®äº† system_promptï¼Œä¼˜å…ˆä½¿ç”¨åœºæ™¯çš„ system_prompt
                                # å¦åˆ™ä½¿ç”¨ç»„åˆçš„ promptï¼ˆåŒ…å«åœºæ™¯è¯¦æƒ…ï¼‰
                                if scenario_config and scenario_config.system_prompt:
                                    # åœºæ™¯æœ‰è‡ªå·±çš„ system_promptï¼Œä½¿ç”¨åœºæ™¯çš„ prompt + ç»„åˆ prompt çš„åœºæ™¯åˆ—è¡¨
                                    agent_config.system_prompt = f"{scenario_config.system_prompt}\n\n{composed_prompt}"
                                    config_sources["system_prompt"] = "SCENARIO_WITH_COMPOSED"
                                    logger.info(f"[session_query_stream] âœ… ä½¿ç”¨åœºæ™¯ system_prompt + ç»„åˆ prompt (length: {len(agent_config.system_prompt)})")
                                else:
                                    # ä½¿ç”¨ç»„åˆçš„ prompt
                                    agent_config.system_prompt = composed_prompt
                                    config_sources["system_prompt"] = "DEFAULT_COMPOSED"
                                    logger.info(f"[session_query_stream] âœ… Generated default system_prompt using PromptComposer (length: {len(composed_prompt)})")
                        except Exception as e:
                            logger.warning(f"[session_query_stream] Failed to generate default system_prompt using PromptComposer: {e}, will use AgentService default")
                            # ç»§ç»­ä½¿ç”¨ AgentService çš„é»˜è®¤å€¼ï¼Œä¸å½±å“ç°æœ‰é€»è¾‘
                    
                    logger.info(f"[session_query_stream] âœ… Applied platform configuration for user_id={current_user.id} BEFORE query")
                    
                    # Save configuration log for this conversation turn
                    try:
                        final_config_dict = {
                            "system_prompt": agent_config.system_prompt,
                            "allowed_tools": agent_config.allowed_tools,
                            "model": agent_config.model,
                            "permission_mode": agent_config.permission_mode,
                            "max_turns": agent_config.max_turns,
                            "cwd": agent_config.cwd,
                            "setting_sources": agent_config.setting_sources,
                            "enabled_skill_ids": agent_config.enabled_skill_ids,
                            "custom_tools": agent_config.custom_tools,
                        }
                        
                        # Get scenario info
                        scenario_id_value = scenario_config.id if scenario_config else None  # ä½¿ç”¨æ•´æ•° id è€Œä¸æ˜¯ scenario_id
                        scenario_name_value = scenario_config.name if scenario_config else None
                        
                        # Save to database (will update session_id later when session is created)
                        await db_service.save_conversation_turn_config(
                            conversation_turn_id=conversation_turn_id,
                            session_id=session_id or "",  # Will be updated when session is created
                            user_id=current_user.id,
                            final_config=final_config_dict,
                            config_sources=config_sources,
                            scenario_id=scenario_id_value,
                            scenario_name=scenario_name_value,
                        )
                        logger.info(f"[session_query_stream] âœ… Saved configuration log for conversation_turn_id={conversation_turn_id}")
                    except Exception as e:
                        logger.error(f"[session_query_stream] Failed to save configuration log: {e}", exc_info=True)
                        # Don't fail the request if config logging fails
                except Exception as e:
                    logger.error(f"[session_query_stream] âŒ Failed to load platform configuration for user_id={current_user.id}: {e}", exc_info=True)
                    # Continue with default configuration (backward compatible)

            # ==================== File Upload and Reference Processing ====================
            # æ–‡ä»¶å¤„ç†é€»è¾‘ï¼šå¦‚æœå¤±è´¥ï¼Œä¸å½±å“æ ¸å¿ƒå¯¹è¯åŠŸèƒ½ï¼Œç»§ç»­ä½¿ç”¨åŸå§‹ prompt
            enhanced_prompt = request.prompt
            uploaded_doc_ids = []
            pending_file_events = []  # å­˜å‚¨å¾…ä¿å­˜çš„æ–‡ä»¶äº‹ä»¶ï¼ˆå½“ session_id å¯ç”¨æ—¶ä¿å­˜ï¼‰
            
            # 1. Process file uploads (if any) - é”™è¯¯å¤„ç†ï¼šå¤±è´¥ä¸å½±å“å¯¹è¯
            if request.attachments and current_user:
                try:
                    file_upload_service = FileUploadService(db_service)
                    for attachment in request.attachments:
                        try:
                            # æ–‡ä»¶ä¸Šä¼ æ—¶ session_id å¯ä»¥ä¸º Noneï¼ˆç¬¬ä¸€æ¬¡å¯¹è¯æ—¶ï¼‰
                            # conversation_turn_id æ˜¯å¿…éœ€çš„ï¼Œå·²åœ¨è¯·æ±‚å¼€å§‹æ—¶ç”Ÿæˆ
                            result = await file_upload_service.save_file_from_base64(
                                base64_data=attachment.data,
                                file_name=attachment.name,
                                user_id=current_user.id,
                                session_id=session_id,  # å¯ä»¥æ˜¯ None
                                conversation_turn_id=conversation_turn_id,  # å¿…éœ€
                            )
                            uploaded_doc_ids.append(result["doc_id"])
                            
                            if result.get("is_existing", False):
                                logger.info(f"[session_query_stream] âœ… File already exists: {result['file_name']} (doc_id: {result['doc_id']})")
                            else:
                                logger.info(f"[session_query_stream] âœ… Uploaded file: {result['file_name']} (doc_id: {result['doc_id']})")
                            
                            # Yield file event to frontend (æ— è®ºæ–‡ä»¶æ˜¯å¦å·²å­˜åœ¨ï¼Œéƒ½å‘é€äº‹ä»¶)
                            # Get file path for the event
                            file_content_loader = FileContentLoader(db_service)
                            file_path = file_content_loader.get_file_path(result['doc_id'], result['file_name'])
                            
                            # ä½¿ç”¨ StreamChunk æ ¼å¼ä¿æŒä¸€è‡´æ€§
                            file_event_data = {
                                    'type': 'file_uploaded',
                                    'doc_id': result['doc_id'],
                                    'file_name': result['file_name'],
                                    'file_type': result['file_type'],
                                    'file_size': result['file_size'],
                                'file_path': str(file_path),
                                    'conversation_turn_id': conversation_turn_id,
                                'is_existing': result.get("is_existing", False),
                            }
                            chunk = StreamChunk(type="file_uploaded", data=file_event_data)
                            logger.info(f"[session_query_stream] ğŸ“¤ Sending file event to frontend: {result['file_name']} (doc_id: {result['doc_id']}, is_existing: {result.get('is_existing', False)}, file_path: {file_path})")
                            yield f"data: {chunk.model_dump_json()}\n\n"
                            
                            # ä¿å­˜æ–‡ä»¶äº‹ä»¶åˆ°æ•°æ®åº“ï¼ˆç”¨äºå¯¹è¯å†å²æ¢å¤ï¼‰
                            # æ³¨æ„ï¼šæ­¤æ—¶ session_id å¯èƒ½è¿˜æ˜¯ Noneï¼ˆç¬¬ä¸€æ¬¡å¯¹è¯ï¼‰ï¼Œéœ€è¦å»¶è¿Ÿä¿å­˜
                            if session_id:
                                try:
                                    await session_mgr.save_message(
                                        session_id=session_id,
                                        role="assistant",
                                        message_type="file_uploaded",
                                        content=str(file_path),
                                        extra_data={
                                            "file_path": str(file_path),
                                            "file_url": result.get("file_url"),
                                            "file_name": result['file_name'],
                                            "file_size": result['file_size'],
                                            "file_type": result['file_type'],
                                            "doc_id": result['doc_id'],
                                        },
                                        conversation_turn_id=conversation_turn_id,
                                    )
                                    logger.debug(f"[session_query_stream] âœ… Saved file_uploaded event to database: {result['file_name']}")
                                except Exception as e:
                                    logger.warning(f"[session_query_stream] Failed to save file_uploaded event to database: {e}")
                            else:
                                # session_id è¿˜æœªåˆ›å»ºï¼Œä¿å­˜åˆ°å¾…å¤„ç†åˆ—è¡¨ï¼Œç¨åé€šè¿‡ deferred binding ä¿å­˜
                                pending_file_events.append({
                                    "file_path": str(file_path),
                                    "file_url": result.get("file_url"),
                                    "file_name": result['file_name'],
                                    "file_size": result['file_size'],
                                    "file_type": result['file_type'],
                                    "doc_id": result['doc_id'],
                                })
                                logger.debug(f"[session_query_stream] â³ File event queued for later save: {result['file_name']}")
                        except Exception as e:
                            # å•ä¸ªæ–‡ä»¶ä¸Šä¼ å¤±è´¥ï¼Œå°è¯•æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å·²å­˜åœ¨
                            logger.warning(f"[session_query_stream] File upload failed for {attachment.name}, checking if file exists: {e}")
                            
                            # Try to find existing file by hash
                            try:
                                import hashlib
                                import base64 as b64
                                # Decode to get file hash
                                if ',' in attachment.data:
                                    base64_data = attachment.data.split(',')[1]
                                else:
                                    base64_data = attachment.data
                                file_data = b64.b64decode(base64_data)
                                file_hash = hashlib.sha256(file_data).hexdigest()[:16]
                                doc_id = f"user-upload-{current_user.id}-{file_hash}"
                                
                                # Check if file exists
                                relationship = await db_service.get_file_relationship(doc_id)
                                if relationship:
                                    uploaded_doc_ids.append(doc_id)
                                    logger.info(f"[session_query_stream] âœ… Found existing file: {relationship.file_name} (doc_id: {doc_id})")
                                    
                                    # Yield file event
                                    # Get file path for the event
                                    file_content_loader = FileContentLoader(db_service)
                                    file_path = file_content_loader.get_file_path(doc_id, relationship.file_name)
                                    
                                    # ä½¿ç”¨ StreamChunk æ ¼å¼ä¿æŒä¸€è‡´æ€§
                                    file_event_data = {
                                        'type': 'file_uploaded',
                                        'doc_id': doc_id,
                                        'file_name': relationship.file_name,
                                        'file_type': relationship.file_type,
                                        'file_size': relationship.file_size,
                                        'file_path': str(file_path),
                                        'conversation_turn_id': conversation_turn_id,
                                        'is_existing': True,
                                    }
                                    chunk = StreamChunk(type="file_uploaded", data=file_event_data)
                                    logger.info(f"[session_query_stream] ğŸ“¤ Sending existing file event to frontend: {relationship.file_name} (doc_id: {doc_id}, file_path: {file_path})")
                                    yield f"data: {chunk.model_dump_json()}\n\n"
                                else:
                                    # File doesn't exist, send error
                                    logger.error(f"[session_query_stream] File upload failed and file doesn't exist: {attachment.name}")
                                    error_event_data = {
                                        'type': 'error',
                                        'data': {
                                            'type': 'error',
                                            'message': f'æ–‡ä»¶ä¸Šä¼ å¤±è´¥: {attachment.name}',
                                        }
                                    }
                                    yield f"data: {json.dumps(error_event_data)}\n\n"
                            except Exception as recovery_error:
                                logger.error(f"[session_query_stream] Failed to recover from upload error: {recovery_error}")
                                # Send error notification
                            error_event_data = {
                                'type': 'error',
                                'data': {
                                    'type': 'error',
                                    'message': f'æ–‡ä»¶ä¸Šä¼ å¤±è´¥: {attachment.name}',
                                }
                            }
                            yield f"data: {json.dumps(error_event_data)}\n\n"
                except Exception as e:
                    # æ–‡ä»¶ä¸Šä¼ æœåŠ¡åˆå§‹åŒ–å¤±è´¥ï¼Œè®°å½•é”™è¯¯ä½†ç»§ç»­å¯¹è¯
                    logger.error(f"[session_query_stream] Failed to process file uploads: {e}", exc_info=True)
                    # ä¸å½±å“æ ¸å¿ƒåŠŸèƒ½ï¼Œç»§ç»­ä½¿ç”¨åŸå§‹ prompt
            
            # 2. Process file references and intents - é”™è¯¯å¤„ç†ï¼šå¤±è´¥ä¸å½±å“å¯¹è¯
            if current_user:
                try:
                    file_reference_parser = FileReferenceParser()
                    file_intent_detector = FileIntentDetector()
                    file_search_service = FileSearchService(db_service)
                    file_content_loader = FileContentLoader(db_service)
                    
                    # Parse explicit file references
                    explicit_refs = file_reference_parser.parse_references(enhanced_prompt)
                    
                    # Detect file intent
                    intent = file_intent_detector.detect_intent(enhanced_prompt)
                    
                    file_context = ""
                    
                    if explicit_refs:
                        # Process explicit file references
                        for ref in explicit_refs:
                            try:
                                if ref.type == "doc_id":
                                    # For explicit doc_id references, provide file path and summary instead of full content
                                    relationship = await db_service.get_file_relationship(ref.value)
                                    if relationship:
                                        file_path = file_content_loader.get_file_path(ref.value, relationship.file_name)
                                        file_context += f"\n\næ–‡ä»¶ï¼š{relationship.file_name} (doc_id: {ref.value})\n"
                                        file_context += f"æ–‡ä»¶è·¯å¾„ï¼š{file_path}\n"
                                        if ref.section:
                                            file_context += f"ç« èŠ‚ï¼š{ref.section}\n"
                                        
                                        # For small files, provide summary; for large files, just path
                                        if relationship.file_size < 10000:  # < 10KB
                                            try:
                                                summary = await file_content_loader.get_file_summary(
                                                    doc_id=ref.value,
                                                    max_lines=50,
                                                    user_id=current_user.id
                                                )
                                                file_context += f"æ–‡ä»¶é¢„è§ˆï¼š\n{summary}\n"
                                            except:
                                                file_context += "ï¼ˆå¦‚éœ€æŸ¥çœ‹å®Œæ•´å†…å®¹ï¼Œè¯·ä½¿ç”¨ Read å·¥å…·è¯»å–ä¸Šè¿°è·¯å¾„ï¼‰\n"
                                        else:
                                            file_context += f"æ–‡ä»¶å¤§å°ï¼š{relationship.file_size} å­—èŠ‚\n"
                                            file_context += "ï¼ˆæ–‡ä»¶è¾ƒå¤§ï¼Œå¦‚éœ€æŸ¥çœ‹å†…å®¹ï¼Œè¯·ä½¿ç”¨ Read å·¥å…·è¯»å–ä¸Šè¿°è·¯å¾„ï¼‰\n"
                                    
                                    # Replace reference in prompt
                                    if ref.original_mention:
                                        enhanced_prompt = enhanced_prompt.replace(
                                            ref.original_mention,
                                            f"[æ–‡ä»¶: {relationship.file_name}]"
                                        )
                                elif ref.type == "mention":
                                    # @mention format - search by file name
                                    files = await file_search_service.search_by_file_name(
                                        user_id=current_user.id,
                                        session_id=session_id,
                                        file_name=ref.value,
                                        limit=1
                                    )
                                    if files:
                                        file = files[0]
                                        relationship = await db_service.get_file_relationship(file.doc_id)
                                        if relationship:
                                            file_path = file_content_loader.get_file_path(file.doc_id, relationship.file_name)
                                            file_context += f"\n\næ–‡ä»¶ï¼š{relationship.file_name} (doc_id: {file.doc_id})\n"
                                            file_context += f"æ–‡ä»¶è·¯å¾„ï¼š{file_path}\n"
                                            
                                            # For small files, provide summary; for large files, just path
                                            if relationship.file_size < 10000:  # < 10KB
                                                try:
                                                    summary = await file_content_loader.get_file_summary(
                                                        doc_id=file.doc_id,
                                                        max_lines=50,
                                                        user_id=current_user.id
                                                    )
                                                    file_context += f"æ–‡ä»¶é¢„è§ˆï¼š\n{summary}\n"
                                                except:
                                                    file_context += "ï¼ˆå¦‚éœ€æŸ¥çœ‹å®Œæ•´å†…å®¹ï¼Œè¯·ä½¿ç”¨ Read å·¥å…·è¯»å–ä¸Šè¿°è·¯å¾„ï¼‰\n"
                                            else:
                                                file_context += f"æ–‡ä»¶å¤§å°ï¼š{relationship.file_size} å­—èŠ‚\n"
                                                file_context += "ï¼ˆæ–‡ä»¶è¾ƒå¤§ï¼Œå¦‚éœ€æŸ¥çœ‹å†…å®¹ï¼Œè¯·ä½¿ç”¨ Read å·¥å…·è¯»å–ä¸Šè¿°è·¯å¾„ï¼‰\n"
                                        
                                        # Replace mention in prompt
                                        if ref.original_mention:
                                            enhanced_prompt = enhanced_prompt.replace(
                                                ref.original_mention,
                                                f"[æ–‡ä»¶: {relationship.file_name}]"
                                            )
                            except Exception as e:
                                # å•ä¸ªæ–‡ä»¶å¼•ç”¨å¤„ç†å¤±è´¥ï¼Œè®°å½•é”™è¯¯ä½†ç»§ç»­å¤„ç†å…¶ä»–å¼•ç”¨
                                logger.error(f"[session_query_stream] Failed to process file reference {ref}: {e}", exc_info=True)
                                # ä¸å½±å“æ ¸å¿ƒåŠŸèƒ½ï¼Œç»§ç»­å¤„ç†
                    
                    elif intent.needs_search:
                        # Process file query intent
                        if intent.type == "file_query":
                            # Search for files
                            files = await file_search_service.search_by_natural_language(
                                user_id=current_user.id,
                                session_id=session_id,
                                query=enhanced_prompt,
                                limit=5
                            )
                            if files:
                                file_list = "\n\næ‰¾åˆ°ä»¥ä¸‹ç›¸å…³æ–‡ä»¶ï¼š\n"
                                for i, file in enumerate(files, 1):
                                    file_list += f"{i}. {file.doc_id} - {file.file_name} (ä¸Šä¼ äº {file.uploaded_at.isoformat() if file.uploaded_at else 'æœªçŸ¥'})\n"
                                file_context = file_list + "\nè¯·å›ç­”ç”¨æˆ·ï¼Œå¹¶è¯¢é—®ç”¨æˆ·è¦æŸ¥çœ‹å“ªä¸ªæ–‡ä»¶ã€‚"
                        elif intent.type == "content_query":
                            # Priority 1: Check if files were uploaded in current turn
                            files = []
                            if uploaded_doc_ids:
                                # Use files uploaded in current turn
                                for doc_id in uploaded_doc_ids:
                                    relationship = await db_service.get_file_relationship(doc_id)
                                    if relationship:
                                        from services.file_search_service import FileInfo
                                        file_info = FileInfo(relationship)
                                        files.append(file_info)
                                logger.info(f"[session_query_stream] Found {len(files)} file(s) uploaded in current turn for content query")
                            
                            # Priority 2: Check files in current conversation turn
                            if not files and conversation_turn_id:
                                try:
                                    turn_files = await db_service.get_turn_files(
                                        conversation_turn_id=conversation_turn_id,
                                        user_id=current_user.id
                                    )
                                    if turn_files:
                                        from services.file_search_service import FileInfo
                                        files = [FileInfo(rel) for rel in turn_files]
                                        logger.info(f"[session_query_stream] Found {len(files)} file(s) in current conversation turn for content query")
                                except Exception as e:
                                    logger.debug(f"[session_query_stream] Failed to get turn files: {e}")
                            
                            # Priority 3: Search by natural language query
                            if not files:
                                files = await file_search_service.search_by_natural_language(
                                    user_id=current_user.id,
                                    session_id=session_id,
                                    query=enhanced_prompt,
                                    limit=1
                                )
                                if files:
                                    logger.info(f"[session_query_stream] Found {len(files)} file(s) via search for content query")
                            
                            if files:
                                file = files[0]
                                relationship = await db_service.get_file_relationship(file.doc_id)
                                if relationship:
                                    file_path = file_content_loader.get_file_path(file.doc_id, relationship.file_name)
                                    file_context = f"\n\næ‰¾åˆ°ç›¸å…³æ–‡ä»¶ï¼š{relationship.file_name} (doc_id: {file.doc_id})\n"
                                    file_context += f"æ–‡ä»¶è·¯å¾„ï¼š{file_path}\n"
                                    
                                    # Use query-based retrieval to get relevant content snippets
                                    # This is more efficient than loading entire file
                                    try:
                                        relevant_content = await file_content_loader.get_file_content_by_query(
                                            doc_id=file.doc_id,
                                            query=enhanced_prompt,  # Use user query to find relevant snippets
                                            user_id=current_user.id,
                                            max_length=5000,  # Limit content to avoid token overflow
                                        )
                                        file_context += f"\næ–‡ä»¶ç›¸å…³å†…å®¹ï¼ˆåŸºäºæŸ¥è¯¢æ£€ç´¢ï¼‰ï¼š\n{relevant_content}\n"
                                        enhanced_prompt = f"ç”¨æˆ·è¯¢é—®å…³äºæ–‡ä»¶ {relationship.file_name} çš„å†…å®¹ï¼š{enhanced_prompt}\n\næ–‡ä»¶ç›¸å…³å†…å®¹ï¼ˆåŸºäºæŸ¥è¯¢æ£€ç´¢ï¼‰ï¼š\n{relevant_content}"
                                        logger.info(f"[session_query_stream] âœ… Used query-based retrieval for file {file.doc_id}, query: {enhanced_prompt[:100]}")
                                    except Exception as e:
                                        logger.warning(f"[session_query_stream] Query-based retrieval failed, falling back to summary: {e}")
                                        # Fallback to summary for small files
                                    if relationship.file_size < 10000:  # < 10KB
                                        try:
                                            summary = await file_content_loader.get_file_summary(
                                                doc_id=file.doc_id,
                                                    max_lines=100,
                                                user_id=current_user.id
                                            )
                                            file_context += f"æ–‡ä»¶é¢„è§ˆï¼š\n{summary}\n"
                                            enhanced_prompt = f"ç”¨æˆ·è¯¢é—®å…³äºæ–‡ä»¶ {relationship.file_name} çš„å†…å®¹ï¼š{enhanced_prompt}\n\næ–‡ä»¶é¢„è§ˆï¼š\n{summary}"
                                        except:
                                            file_context += "ï¼ˆå¦‚éœ€æŸ¥çœ‹å®Œæ•´å†…å®¹ï¼Œè¯·ä½¿ç”¨ Read å·¥å…·è¯»å–ä¸Šè¿°è·¯å¾„ï¼‰\n"
                                            enhanced_prompt = f"ç”¨æˆ·è¯¢é—®å…³äºæ–‡ä»¶ {relationship.file_name} çš„å†…å®¹ï¼š{enhanced_prompt}\n\næ–‡ä»¶è·¯å¾„ï¼š{file_path}"
                                    else:
                                        file_context += f"æ–‡ä»¶å¤§å°ï¼š{relationship.file_size} å­—èŠ‚\n"
                                        file_context += "ï¼ˆæ–‡ä»¶è¾ƒå¤§ï¼Œå¦‚éœ€æŸ¥çœ‹å†…å®¹ï¼Œè¯·ä½¿ç”¨ Read å·¥å…·è¯»å–ä¸Šè¿°è·¯å¾„ï¼‰\n"
                                        enhanced_prompt = f"ç”¨æˆ·è¯¢é—®å…³äºæ–‡ä»¶ {relationship.file_name} çš„å†…å®¹ï¼š{enhanced_prompt}\n\næ–‡ä»¶è·¯å¾„ï¼š{file_path}"
                    
                    # Add file context to prompt
                    if file_context:
                        enhanced_prompt = enhanced_prompt + file_context
                        logger.info(f"[session_query_stream] âœ… Added file context to prompt (length: {len(file_context)} chars)")
                
                except Exception as e:
                    # æ–‡ä»¶å¼•ç”¨å¤„ç†å¤±è´¥ï¼Œè®°å½•é”™è¯¯ä½†ç»§ç»­ä½¿ç”¨åŸå§‹ prompt
                    logger.error(f"[session_query_stream] Failed to process file references: {e}", exc_info=True)
                    # ä¸å½±å“æ ¸å¿ƒåŠŸèƒ½ï¼Œç»§ç»­ä½¿ç”¨åŸå§‹ prompt
                    enhanced_prompt = request.prompt
            
            # 3. If files were uploaded in this turn, provide file info and path (NOT full content)
            # This avoids loading large files into prompt, letting Claude use Read tool when needed
            if uploaded_doc_ids and current_user:
                try:
                    file_content_loader = FileContentLoader(db_service)
                    upload_context = "\n\nç”¨æˆ·åœ¨å½“å‰å¯¹è¯ä¸­ä¸Šä¼ äº†ä»¥ä¸‹æ–‡ä»¶ï¼š\n"
                    for doc_id in uploaded_doc_ids:
                        try:
                            relationship = await db_service.get_file_relationship(doc_id)
                            if relationship:
                                # Get file path
                                file_path = file_content_loader.get_file_path(doc_id, relationship.file_name)
                                
                                # For small text files (< 5KB), provide a summary
                                # For larger files, just provide path and let Claude use Read tool
                                if relationship.file_size < 5000 and relationship.file_type.startswith('text/'):
                                    try:
                                        summary = await file_content_loader.get_file_summary(
                                            doc_id=doc_id,
                                            max_lines=30,  # Only first 30 lines
                                            user_id=current_user.id
                                        )
                                        upload_context += f"\næ–‡ä»¶ï¼š{relationship.file_name}\n"
                                        upload_context += f"æ–‡ä»¶è·¯å¾„ï¼š{file_path}\n"
                                        upload_context += f"æ–‡ä»¶å¤§å°ï¼š{relationship.file_size} å­—èŠ‚\n"
                                        upload_context += f"æ–‡ä»¶ç±»å‹ï¼š{relationship.file_type}\n"
                                        upload_context += f"æ–‡ä»¶é¢„è§ˆï¼ˆå‰30è¡Œï¼‰ï¼š\n{summary}\n"
                                        upload_context += "---\n"
                                    except Exception as e:
                                        logger.warning(f"[session_query_stream] Failed to get file summary for {doc_id}: {e}")
                                        # Fallback to just path info
                                        upload_context += f"\næ–‡ä»¶ï¼š{relationship.file_name}\n"
                                        upload_context += f"æ–‡ä»¶è·¯å¾„ï¼š{file_path}\n"
                                        upload_context += f"æ–‡ä»¶å¤§å°ï¼š{relationship.file_size} å­—èŠ‚\n"
                                        upload_context += f"æ–‡ä»¶ç±»å‹ï¼š{relationship.file_type}\n"
                                        upload_context += "ï¼ˆå¦‚éœ€æŸ¥çœ‹æ–‡ä»¶å†…å®¹ï¼Œè¯·ä½¿ç”¨ Read å·¥å…·è¯»å–ä¸Šè¿°è·¯å¾„ï¼‰\n"
                                        upload_context += "---\n"
                                else:
                                    # For larger files or non-text files, just provide path
                                    upload_context += f"\næ–‡ä»¶ï¼š{relationship.file_name}\n"
                                    upload_context += f"æ–‡ä»¶è·¯å¾„ï¼š{file_path}\n"
                                    upload_context += f"æ–‡ä»¶å¤§å°ï¼š{relationship.file_size} å­—èŠ‚\n"
                                    upload_context += f"æ–‡ä»¶ç±»å‹ï¼š{relationship.file_type}\n"
                                    upload_context += "ï¼ˆå¦‚éœ€æŸ¥çœ‹æ–‡ä»¶å†…å®¹ï¼Œè¯·ä½¿ç”¨ Read å·¥å…·è¯»å–ä¸Šè¿°è·¯å¾„ï¼‰\n"
                                    upload_context += "---\n"
                        except Exception as e:
                            logger.error(f"[session_query_stream] Failed to process uploaded file {doc_id}: {e}", exc_info=True)
                            # If processing fails, at least mention the file
                            try:
                                relationship = await db_service.get_file_relationship(doc_id)
                                if relationship:
                                    upload_context += f"\næ–‡ä»¶ï¼š{relationship.file_name} (doc_id: {doc_id}) - æ–‡ä»¶ä¿¡æ¯è·å–å¤±è´¥\n"
                            except:
                                pass
                    
                    enhanced_prompt = enhanced_prompt + upload_context
                    logger.info(f"[session_query_stream] âœ… Added uploaded file info to prompt (files: {len(uploaded_doc_ids)}, NOT loading full content)")
                except Exception as e:
                    logger.error(f"[session_query_stream] Failed to process uploaded files: {e}", exc_info=True)
                    # Fallback: just mention files without details
                    upload_context = "\n\nç”¨æˆ·åœ¨å½“å‰å¯¹è¯ä¸­ä¸Šä¼ äº†ä»¥ä¸‹æ–‡ä»¶ï¼š\n"
                    for doc_id in uploaded_doc_ids:
                        try:
                            relationship = await db_service.get_file_relationship(doc_id)
                            if relationship:
                                upload_context += f"- {relationship.file_name} (doc_id: {doc_id})\n"
                        except:
                            pass
                    enhanced_prompt = enhanced_prompt + upload_context

            # ğŸš€ å¼€å§‹æŸ¥è¯¢ï¼ˆåœ¨ä¸» try å—å†…ï¼‰
            async for msg in agent_service.query_in_session(
                prompt=enhanced_prompt,  # Use enhanced prompt with file context
                session_id=session_id or "",  # Empty string for first query
                include_partial_messages=request.incremental_stream,  # ä¼ é€’å¢é‡æµå¼å‚æ•°
                session_manager=session_mgr,  # ä¼ é€’ session_manager ç”¨äºæ£€æŸ¥æ¶ˆæ¯è®°å½•
                agent_config=agent_config,  # ä¼ é€’å¹³å°é…ç½®
                user_id=current_user.id if current_user else None,  # ä¼ é€’ user_id ç”¨äºç”Ÿæˆ work_dir
            ):
                # å¤„ç† SystemMessage - æå– session_idï¼ˆç¬¬ä¸€æ¬¡æŸ¥è¯¢æ—¶ï¼‰
                if isinstance(msg, SystemMessage) and msg.subtype == "init":
                    # ä» SystemMessage çš„ data ä¸­æå– session_id
                    if isinstance(msg.data, dict) and "session_id" in msg.data:
                        extracted_session_id = msg.data.get("session_id")
                        if extracted_session_id and not session_id:
                            session_id = extracted_session_id
                            logger.info(f"[session_query_stream] Extracted session_id from SystemMessage: {session_id}")
                            
                            # ==================== å»¶è¿Ÿç»‘å®š session_id ====================
                            # å½“ session_id å¯ç”¨æ—¶ï¼Œæ‰¹é‡æ›´æ–° conversation_turn_id ç›¸å…³çš„è®°å½•
                            if current_user:
                                try:
                                    updated_count = await db_service.update_session_id_for_turn(
                                        conversation_turn_id=conversation_turn_id,
                                        session_id=session_id,
                                        user_id=current_user.id
                                    )
                                    logger.info(
                                        f"[session_query_stream] âœ… Bound session_id={session_id} "
                                        f"to {updated_count} records for conversation_turn_id={conversation_turn_id}"
                                    )
                                    
                                    # ä¿å­˜å¾…å¤„ç†çš„æ–‡ä»¶äº‹ä»¶åˆ°æ•°æ®åº“
                                    if pending_file_events:
                                        for file_event in pending_file_events:
                                            try:
                                                file_content_loader = FileContentLoader(db_service)
                                                file_path = file_content_loader.get_file_path(file_event['doc_id'], file_event['file_name'])
                                                await session_mgr.save_message(
                                                    session_id=session_id,
                                                    role="assistant",
                                                    message_type="file_uploaded",
                                                    content=str(file_path),
                                                    extra_data={
                                                        "file_path": str(file_path),
                                                        "file_url": file_event.get("file_url"),
                                                        "file_name": file_event['file_name'],
                                                        "file_size": file_event['file_size'],
                                                        "file_type": file_event['file_type'],
                                                        "doc_id": file_event['doc_id'],
                                                    },
                                                    conversation_turn_id=conversation_turn_id,
                                                )
                                                logger.debug(f"[session_query_stream] âœ… Saved queued file_uploaded event: {file_event['file_name']}")
                                            except Exception as e:
                                                logger.warning(f"[session_query_stream] Failed to save queued file event: {e}")
                                        logger.info(f"[session_query_stream] âœ… Saved {len(pending_file_events)} queued file events to database")
                                        pending_file_events.clear()
                                except Exception as e:
                                    logger.error(
                                        f"[session_query_stream] Failed to bind session_id: {e}", 
                                        exc_info=True
                                    )
                                    # ä¸å½±å“æ ¸å¿ƒåŠŸèƒ½ï¼Œç»§ç»­æ‰§è¡Œ
                            
                            # åˆ›å»ºä¼šè¯è®°å½•ï¼ˆå¦‚æœè¿˜æ²¡æœ‰åˆ›å»ºï¼‰
                            if not session_created:
                                try:
                                    # ä»æ•°æ®åº“æ£€æŸ¥ä¼šè¯æ˜¯å¦å·²å­˜åœ¨
                                    db_session = await db_service.get_session(session_id)
                                    if not db_session:
                                        # åˆ›å»ºæ–°çš„ä¼šè¯è®°å½•ï¼Œç»‘å®šåˆ°å½“å‰ç”¨æˆ·
                                        user_id = current_user.id if current_user else None
                                        
                                        # Note: conversation_turn_config çš„ session_id å·²åœ¨ä¸Šé¢æ‰¹é‡æ›´æ–°
                                        # è¿™é‡Œåªéœ€è¦åˆ›å»ºä¼šè¯è®°å½•
                                        await db_service.create_session(
                                            session_id=session_id,
                                            user_id=user_id,
                                            system_prompt=agent_config.system_prompt if agent_config else None,
                                            model=agent_config.model if agent_config else None,
                                            allowed_tools=agent_config.allowed_tools if agent_config else None,
                                            permission_mode=agent_config.permission_mode if agent_config else None,
                                            max_turns=agent_config.max_turns if agent_config else None,
                                        )
                                        logger.info(f"[session_query_stream] âœ… Created session record: {session_id} for user: {user_id}")
                                    else:
                                        logger.info(f"[session_query_stream] Session {session_id} already exists in database")
                                    
                                    session_created = True
                                except Exception as e:
                                    logger.error(f"[session_query_stream] Failed to create session record: {e}", exc_info=True)
                                    # ä¸å½±å“æ ¸å¿ƒåŠŸèƒ½ï¼Œç»§ç»­æ‰§è¡Œ
                            
                            # æ›´æ–°å·²ä¿å­˜çš„ç”¨æˆ·æ¶ˆæ¯çš„ session_idï¼ˆå¦‚æœæœ‰ï¼‰
                            if user_message_saved and user_message_id:
                                try:
                                    # ç”¨æˆ·æ¶ˆæ¯çš„ session_id åº”è¯¥å·²ç»æ­£ç¡®è®¾ç½®ï¼ˆå¦‚æœæœ‰ session_idï¼‰
                                    # è¿™é‡Œä¸»è¦æ˜¯ç¡®ä¿ conversation_turn_id æ­£ç¡®å…³è”
                                    pass  # ç”¨æˆ·æ¶ˆæ¯å·²åœ¨ä¿å­˜æ—¶è®¾ç½®äº†æ­£ç¡®çš„ session_id
                                except Exception as e:
                                    logger.warning(f"[session_query_stream] Failed to update user message: {e}")
                                    
                            # ä¿å­˜ç”¨æˆ·æ¶ˆæ¯ï¼ˆå¦‚æœè¿˜æ²¡æœ‰ä¿å­˜ï¼Œç°åœ¨æœ‰äº† session_idï¼‰
                            if not user_message_saved:
                                try:
                                    user_message_id = await session_mgr.save_message(
                                        session_id=session_id,
                                        role="user",
                                        message_type="text",
                                        content=request.prompt,
                                        conversation_turn_id=conversation_turn_id,
                                    )
                                    user_message_saved = True
                                    logger.info(f"[session_query_stream] âœ… Saved user message with session_id={session_id}")
                                except Exception as e:
                                    logger.error(f"[session_query_stream] Failed to save user message: {e}", exc_info=True)
                
                # å¤„ç†å¢é‡æµå¼æ–‡æœ¬ç‰‡æ®µ
                if isinstance(msg, ContentBlock) and msg.type == "text_delta":
                    # ğŸ”§ ä¿®å¤ï¼šæ”¶é›† text_delta å†…å®¹åˆ° assistant_contentï¼Œç¡®ä¿å®Œæ•´ä¿å­˜
                    if msg.text:
                        assistant_content.append(msg.text)
                    chunk = StreamChunk(type="text_delta", data=msg)
                    yield f"data: {chunk.model_dump_json()}\n\n"
                elif isinstance(msg, ContentBlock) and msg.type == "tool_start":
                    # ğŸ”§ å¤„ç†å·¥å…·è°ƒç”¨å¼€å§‹äº‹ä»¶ï¼Œç»´æŠ¤ index -> tool_use_id æ˜ å°„
                    logger.info(f"[session_query_stream] ğŸ” Received tool_start: tool_use_id={msg.tool_use_id[:20]}..., tool_input={msg.tool_input}")
                    if msg.tool_input and isinstance(msg.tool_input, dict) and '_index' in msg.tool_input:
                        index = msg.tool_input.pop('_index')  # ç§»é™¤ä¸´æ—¶æ·»åŠ çš„ index
                        tool_use_index_map[index] = msg.tool_use_id
                        logger.info(f"[session_query_stream] âœ… Mapped tool_use: index={index} -> tool_use_id={msg.tool_use_id[:20]}...")
                        
                        # ğŸ”§ å…ˆå‘é€ tool_start äº‹ä»¶ï¼Œè®©å‰ç«¯å»ºç«‹æ˜ å°„
                        chunk = StreamChunk(type="data", data=msg)
                        chunk_json = chunk.model_dump_json()
                        logger.info(f"[session_query_stream] ğŸ“¤ å‘é€ tool_start åˆ°å‰ç«¯: chunk_type={chunk.type}, data_type={msg.type}, tool_use_id={msg.tool_use_id[:20]}..., chunk_json_length={len(chunk_json)}")
                        yield f"data: {chunk_json}\n\n"
                        
                        # ğŸ”§ ç„¶åå¤„ç†å¹¶å‘é€ç¼“å­˜çš„ tool_input_delta äº‹ä»¶ï¼ˆç¡®ä¿å‰ç«¯å·²å¤„ç† toolStartï¼‰
                        if index in pending_tool_input_deltas:
                            cached_deltas = pending_tool_input_deltas.pop(index)
                            logger.info(f"[session_query_stream] ğŸ”„ Processing {len(cached_deltas)} cached tool_input_delta events for index={index} (after tool_start)")
                            for cached_delta in cached_deltas:
                                # æ›´æ–° tool_use_id
                                cached_delta.tool_use_id = msg.tool_use_id
                                chunk = StreamChunk(type="data", data=cached_delta)
                                chunk_json = chunk.model_dump_json()
                                logger.info(f"[session_query_stream] ğŸ“¤ å‘é€ç¼“å­˜çš„ tool_input_delta åˆ°å‰ç«¯: chunk_type={chunk.type}, data_type={cached_delta.type}, tool_use_id={msg.tool_use_id[:20]}..., partial_json_length={len(cached_delta.text) if cached_delta.text else 0}, chunk_json_length={len(chunk_json)}")
                                yield f"data: {chunk_json}\n\n"
                    else:
                        logger.warning(f"[session_query_stream] âš ï¸ tool_start: tool_input is None or missing _index, tool_input={msg.tool_input}")
                        # å³ä½¿æ²¡æœ‰ _indexï¼Œä¹Ÿå‘é€ tool_start äº‹ä»¶
                        chunk = StreamChunk(type="data", data=msg)
                        yield f"data: {chunk.model_dump_json()}\n\n"
                elif isinstance(msg, ContentBlock) and msg.type == "tool_input_delta":
                    # ğŸ”§ å¤„ç†å·¥å…·è°ƒç”¨çš„æµå¼è¾“å…¥æ›´æ–°ï¼ˆinput_json_deltaï¼‰
                    # msg.tool_use_id ä¸´æ—¶å­˜å‚¨çš„æ˜¯ indexï¼ˆå­—ç¬¦ä¸²å½¢å¼ï¼‰
                    index = int(msg.tool_use_id) if msg.tool_use_id and msg.tool_use_id.isdigit() else None
                    logger.info(f"[session_query_stream] ğŸ” Received tool_input_delta: index={index}, tool_use_id={msg.tool_use_id}, tool_use_index_map={list(tool_use_index_map.keys())}")
                    if index is not None and index in tool_use_index_map:
                        # æ‰¾åˆ°å¯¹åº”çš„ tool_use_idï¼Œæ›´æ–° ContentBlock
                        actual_tool_use_id = tool_use_index_map[index]
                        msg.tool_use_id = actual_tool_use_id
                        logger.info(f"[session_query_stream] âœ… Found mapping: index={index} -> tool_use_id={actual_tool_use_id[:20]}..., sending to frontend")
                        chunk = StreamChunk(type="data", data=msg)
                        chunk_json = chunk.model_dump_json()
                        logger.info(f"[session_query_stream] ğŸ“¤ å‘é€ tool_input_delta åˆ°å‰ç«¯: chunk_type={chunk.type}, data_type={msg.type}, tool_use_id={actual_tool_use_id[:20]}..., partial_json_length={len(msg.text) if msg.text else 0}, chunk_json_length={len(chunk_json)}")
                        yield f"data: {chunk_json}\n\n"
                    else:
                        # ğŸ”§ å¦‚æœæ‰¾ä¸åˆ°æ˜ å°„ï¼Œç¼“å­˜èµ·æ¥ï¼Œç­‰å¾… tool_start äº‹ä»¶å»ºç«‹æ˜ å°„
                        if index is not None:
                            if index not in pending_tool_input_deltas:
                                pending_tool_input_deltas[index] = []
                            pending_tool_input_deltas[index].append(msg)
                            logger.info(f"[session_query_stream] â³ Cached tool_input_delta: index={index}, waiting for tool_start (total cached: {len(pending_tool_input_deltas[index])})")
                        else:
                            logger.warning(f"[session_query_stream] âš ï¸ tool_input_delta: invalid index={index}, tool_use_id={msg.tool_use_id}")
                elif isinstance(msg, ContentBlock) and msg.type == "tool_result":
                    # å¤„ç†å·¥å…·ç»“æœï¼Œä¿å­˜åˆ°æ•°æ®åº“
                    if session_id and msg.tool_use_id:
                        try:
                            # ç¡®ä¿å·¥å…·è¾“å‡ºä¸ä¸ºç©ºï¼ˆå¦‚æœä¸º Noneï¼Œä½¿ç”¨ç©ºå­—ç¬¦ä¸²ï¼‰
                            tool_output = msg.text if msg.text is not None else ""
                            await session_mgr.save_message(
                                session_id=session_id,
                                role="assistant",
                                message_type="tool_result",
                                content=tool_output,
                                extra_data={
                                    "tool_use_id": msg.tool_use_id,
                                    "is_error": msg.is_error or False,
                                },
                                conversation_turn_id=conversation_turn_id,
                            )
                            logger.info(
                                f"[session_query_stream] âœ… Saved tool_result: tool_use_id={msg.tool_use_id[:20]}..., "
                                f"content_length={len(tool_output) if tool_output else 0}, "
                                f"content_preview={tool_output[:100] if tool_output else '(empty)'}, "
                                f"conversation_turn_id={conversation_turn_id}"
                            )
                        except Exception as e:
                            logger.error(f"[session_query_stream] Error saving tool_result: {e}")
                    
                    chunk = StreamChunk(type="data", data=msg)
                    yield f"data: {chunk.model_dump_json()}\n\n"
                elif isinstance(msg, AssistantMessage):
                    # æ”¶é›† AssistantMessage çš„å†…å®¹
                    text_content = ""
                    for block in msg.content:
                        if block.type == "text" and block.text:
                            text_content += block.text
                        elif block.type == "tool_use":
                            # ğŸ” é‡è¦ï¼šä¿å­˜å·¥å…·è°ƒç”¨åˆ°æ•°æ®åº“ï¼ˆç¡®ä¿åŒä¸€ tool_use_id åªä¿å­˜ä¸€æ¬¡ï¼‰
                            if session_id and block.tool_use_id and block.tool_use_id not in saved_tool_use_ids:
                                try:
                                    await session_mgr.save_message(
                                        session_id=session_id,
                                        role="assistant",
                                        message_type="tool_use",
                                        content="",  # tool_use ä¸éœ€è¦ content
                                        extra_data={
                                            "tool_use_id": block.tool_use_id,
                                            "tool_name": block.tool_name,
                                            "tool_input": block.tool_input,
                                        },
                                        conversation_turn_id=conversation_turn_id,
                                        parent_message_id=assistant_message_id,  # å…³è”åˆ° assistant æ¶ˆæ¯
                                    )
                                    saved_tool_use_ids.add(block.tool_use_id)  # æ ‡è®°ä¸ºå·²ä¿å­˜
                                    logger.info(
                                        f"[session_query_stream] âœ… Saved tool_use: tool_use_id={block.tool_use_id[:20]}..., "
                                        f"tool_name={block.tool_name}, "
                                        f"conversation_turn_id={conversation_turn_id}"
                                    )
                                except Exception as e:
                                    logger.error(f"[session_query_stream] Error saving tool_use: {e}", exc_info=True)
                            
                            # æ”¶é›†å·¥å…·è°ƒç”¨ä¿¡æ¯ï¼ˆç”¨äºåç»­å¤„ç†ï¼‰
                            tool_calls.append({
                                "tool_use_id": block.tool_use_id,
                                "tool_name": block.tool_name,
                                "tool_input": block.tool_input,
                            })
                        elif block.type == "tool_result":
                            # å¤„ç†å·¥å…·ç»“æœï¼Œä¿å­˜åˆ°æ•°æ®åº“
                            if session_id and block.tool_use_id:
                                try:
                                    # ç¡®ä¿å·¥å…·è¾“å‡ºä¸ä¸ºç©ºï¼ˆå¦‚æœä¸º Noneï¼Œä½¿ç”¨ç©ºå­—ç¬¦ä¸²ï¼‰
                                    tool_output = block.text if block.text is not None else ""
                                    await session_mgr.save_message(
                                        session_id=session_id,
                                        role="assistant",
                                        message_type="tool_result",
                                        content=tool_output,
                                        extra_data={
                                            "tool_use_id": block.tool_use_id,
                                            "is_error": block.is_error or False,
                                        },
                                        conversation_turn_id=conversation_turn_id,
                                    )
                                    logger.info(
                                        f"[session_query_stream] âœ… Saved tool_result: tool_use_id={block.tool_use_id[:20]}..., "
                                        f"content_length={len(tool_output) if tool_output else 0}, "
                                        f"content_preview={tool_output[:100] if tool_output else '(empty)'}, "
                                        f"conversation_turn_id={conversation_turn_id}"
                                    )
                                except Exception as e:
                                    logger.error(f"[session_query_stream] Error saving tool_result: {e}")
                        elif block.type in ["file_created", "file_uploaded"]:
                            # å¤„ç†æ–‡ä»¶äº‹ä»¶ï¼Œè®¾ç½® conversation_turn_id å¹¶å•ç‹¬æ¨é€
                            if not block.conversation_turn_id:
                                block.conversation_turn_id = conversation_turn_id
                            # å•ç‹¬æ¨é€æ–‡ä»¶äº‹ä»¶
                            chunk = StreamChunk(type="file_event", data=block)
                            yield f"data: {chunk.model_dump_json()}\n\n"
                            # ä¿å­˜æ–‡ä»¶äº‹ä»¶åˆ°æ•°æ®åº“ï¼ˆå¯é€‰ï¼‰
                            if session_id:
                                try:
                                    await session_mgr.save_message(
                                        session_id=session_id,
                                        role="assistant",
                                        message_type=block.type,
                                        content=block.file_url or block.file_path or "",
                                        extra_data={
                                            "file_path": block.file_path,
                                            "file_url": block.file_url,
                                            "file_name": block.file_name,
                                            "file_size": block.file_size,
                                            "file_type": block.file_type,
                                        },
                                        conversation_turn_id=conversation_turn_id,
                                    )
                                    logger.debug(f"[session_query_stream] Saved {block.type} event")
                                except Exception as e:
                                    logger.error(f"[session_query_stream] Error saving file event: {e}")

                    # ğŸ”§ ä¿®å¤ï¼šä¸è¦å†æ¬¡ append text_content åˆ° assistant_content
                    # å› ä¸º text_delta å·²ç»æ”¶é›†äº†æ‰€æœ‰æ–‡æœ¬å†…å®¹
                    # å¦‚æœå†æ¬¡ appendï¼Œä¼šå¯¼è‡´å†…å®¹é‡å¤
                    # assistant_content.append(text_content)  # â† å·²åˆ é™¤ï¼Œé¿å…é‡å¤

                    # å‘é€å®Œæ•´çš„ AssistantMessageï¼ˆåŒ…å«æ–‡æœ¬å†…å®¹å’Œ tool_use å—ï¼‰
                    # å‰ç«¯ä¼šä» AssistantMessage çš„ content ä¸­æå– tool_use å—
                    chunk = StreamChunk(type="data", data=msg)
                    yield f"data: {chunk.model_dump_json()}\n\n"
                elif isinstance(msg, ResultInfo):
                    # ä¿å­˜ ResultMessage ä¿¡æ¯
                    result_info_dict = {
                        "subtype": msg.subtype,
                        "duration_ms": msg.duration_ms,
                        "duration_api_ms": getattr(msg, 'duration_api_ms', None),
                        "is_error": msg.is_error,
                        "num_turns": msg.num_turns,
                        "session_id": msg.session_id or session_id,  # ä½¿ç”¨æå–çš„ session_id
                        "total_cost_usd": msg.total_cost_usd,
                        "usage": getattr(msg, 'usage', None),
                    }
                    # æ›´æ–° session_idï¼ˆå¦‚æœ ResultInfo ä¸­æœ‰ï¼‰
                    if msg.session_id:
                        session_id = msg.session_id
                    elif not session_id:
                        # å¦‚æœè¿˜æ²¡æœ‰ session_idï¼Œä½¿ç”¨ ResultInfo ä¸­çš„ï¼ˆå¯èƒ½æ˜¯ç©ºå­—ç¬¦ä¸²ï¼‰
                        session_id = msg.session_id
                    
                    # å¦‚æœç”¨æˆ·æ¶ˆæ¯è¿˜æ²¡ä¿å­˜ï¼Œç°åœ¨ä¿å­˜ï¼ˆå› ä¸ºç°åœ¨æœ‰äº† session_idï¼‰
                    if not user_message_saved and session_id:
                        user_message_id = await session_mgr.save_message(
                            session_id=session_id,
                            role="user",
                            message_type="text",
                            content=request.prompt,
                            conversation_turn_id=conversation_turn_id,
                        )
                        user_message_saved = True
                    
                    # ä¿å­˜ AI æ¶ˆæ¯ï¼ˆåŒ…å« result_infoï¼‰
                    if session_id:
                        try:
                            full_text = "".join(assistant_content)
                            # æ¸…ç†æ–‡æœ¬å†…å®¹ï¼Œç§»é™¤æ–‡ä»¶è·¯å¾„å’ŒURLï¼ˆæ–‡ä»¶ä¿¡æ¯å·²é€šè¿‡æ–‡ä»¶äº‹ä»¶å•ç‹¬ä¿å­˜ï¼‰
                            cleaned_text = clean_message_text(full_text)
                            
                            # ğŸ” è°ƒè¯•ï¼šè®°å½•ä¿å­˜å‰çš„çŠ¶æ€
                            logger.info(
                                f"[session_query_stream] ğŸ” Saving AI message: session_id={session_id}, "
                                f"turn_id={conversation_turn_id}, "
                                f"assistant_content_length={len(assistant_content)}, "
                                f"full_text_length={len(full_text)}, "
                                f"cleaned_text_length={len(cleaned_text)}, "
                                f"user_message_id={user_message_id}, "
                                f"tool_calls_count={len(tool_calls)}"
                            )
                            
                            assistant_message_id = await session_mgr.save_message(
                                session_id=session_id,
                                role="assistant",
                                message_type="text",
                                content=cleaned_text,
                                result_info=result_info_dict,
                                conversation_turn_id=conversation_turn_id,
                                parent_message_id=user_message_id,
                            )
                            
                            logger.info(
                                f"[session_query_stream] âœ… Saved AI message: message_id={assistant_message_id}, "
                                f"content_preview={cleaned_text[:100] if cleaned_text else '(empty)'}"
                            )
                            
                            # ä¿å­˜å·¥å…·è°ƒç”¨ï¼ˆtool_useï¼‰
                            for tool_call in tool_calls:
                                try:
                                    await session_mgr.save_message(
                                        session_id=session_id,
                                        role="assistant",
                                        message_type="tool_use",
                                        content=None,
                                        extra_data={
                                            "tool_use_id": tool_call["tool_use_id"],
                                            "tool_name": tool_call["tool_name"],
                                            "tool_input": tool_call["tool_input"],
                                        },
                                        conversation_turn_id=conversation_turn_id,
                                        parent_message_id=assistant_message_id,
                                    )
                                except Exception as tool_error:
                                    logger.error(f"[session_query_stream] âŒ Failed to save tool_call: {tool_error}", exc_info=True)
                            
                            logger.info(f"[session_query_stream] âœ… Saved messages for session: {session_id}, turn_id: {conversation_turn_id}, ai_message_id: {assistant_message_id}, tool_calls: {len(tool_calls)}")
                        except Exception as e:
                            logger.error(f"[session_query_stream] âŒ Failed to save AI message: {e}", exc_info=True)
                    else:
                        logger.warning(f"[session_query_stream] âš ï¸ Cannot save AI message: session_id is None, turn_id: {conversation_turn_id}")
                    
                    chunk = StreamChunk(type="data", data=msg)
                    yield f"data: {chunk.model_dump_json()}\n\n"
                elif isinstance(msg, UserMessage):
                    # å¤„ç† UserMessageï¼ˆåŒ…å«å·¥å…·ç»“æœï¼Œå¯èƒ½åŒ…å«æ–‡ä»¶äº‹ä»¶ï¼‰
                    for block in msg.content:
                        if block.type == "tool_result":
                            # ğŸ” é‡è¦ï¼šå¤„ç† UserMessage ä¸­çš„å·¥å…·ç»“æœï¼Œä¿å­˜åˆ°æ•°æ®åº“
                            if session_id and block.tool_use_id:
                                try:
                                    # ContentBlock ä¸­çš„å·¥å…·ç»“æœå­˜å‚¨åœ¨ text å­—æ®µä¸­ï¼ˆä¸æ˜¯ content å­—æ®µï¼‰
                                    # å› ä¸º _convert_sdk_message å·²ç»å°† ToolResultBlock.content æ ¼å¼åŒ–ä¸º text
                                    tool_output = block.text if hasattr(block, 'text') and block.text is not None else ""
                                    
                                    await session_mgr.save_message(
                                        session_id=session_id,
                                        role="assistant",
                                        message_type="tool_result",
                                        content=tool_output,
                                        extra_data={
                                            "tool_use_id": block.tool_use_id,
                                            "is_error": getattr(block, 'is_error', False) or False,
                                        },
                                        conversation_turn_id=conversation_turn_id,
                                    )
                                    logger.info(
                                        f"[session_query_stream] âœ… Saved tool_result from UserMessage: tool_use_id={block.tool_use_id[:20]}..., "
                                        f"content_length={len(tool_output) if tool_output else 0}, "
                                        f"content_preview={tool_output[:100] if tool_output else '(empty)'}, "
                                        f"conversation_turn_id={conversation_turn_id}"
                                    )
                                except Exception as e:
                                    logger.error(f"[session_query_stream] Error saving tool_result from UserMessage: {e}", exc_info=True)
                            
                            # å‘é€å·¥å…·ç»“æœåˆ°å‰ç«¯
                            chunk = StreamChunk(type="data", data=block)
                            yield f"data: {chunk.model_dump_json()}\n\n"
                        elif block.type in ["file_created", "file_uploaded"]:
                            # å¤„ç†æ–‡ä»¶äº‹ä»¶ï¼Œè®¾ç½® conversation_turn_id å¹¶å•ç‹¬æ¨é€
                            if not block.conversation_turn_id:
                                block.conversation_turn_id = conversation_turn_id
                            # å•ç‹¬æ¨é€æ–‡ä»¶äº‹ä»¶
                            chunk = StreamChunk(type="file_event", data=block)
                            yield f"data: {chunk.model_dump_json()}\n\n"
                            # ä¿å­˜æ–‡ä»¶äº‹ä»¶åˆ°æ•°æ®åº“ï¼ˆå¯é€‰ï¼‰
                            if session_id:
                                try:
                                    await session_mgr.save_message(
                                        session_id=session_id,
                                        role="assistant",
                                        message_type=block.type,
                                        content=block.file_url or block.file_path or "",
                                        extra_data={
                                            "file_path": block.file_path,
                                            "file_url": block.file_url,
                                            "file_name": block.file_name,
                                            "file_size": block.file_size,
                                            "file_type": block.file_type,
                                        },
                                        conversation_turn_id=conversation_turn_id,
                                    )
                                    logger.debug(f"[session_query_stream] Saved {block.type} event from UserMessage")
                                except Exception as e:
                                    logger.error(f"[session_query_stream] Error saving file event from UserMessage: {e}")
                    # å‘é€å®Œæ•´çš„ UserMessage
                    chunk = StreamChunk(type="data", data=msg)
                    yield f"data: {chunk.model_dump_json()}\n\n"
                else:
                    chunk = StreamChunk(type="data", data=msg)
                    yield f"data: {chunk.model_dump_json()}\n\n"

            logger.info(f"[session_query_stream] Query completed for session {session_id or 'new session'}")

            # å‘é€æµç»“æŸæ ‡è®°
            end_chunk = StreamChunk(type="end", data={"status": "completed"})
            yield f"data: {end_chunk.model_dump_json()}\n\n"

        except Exception as e:
            logger.error(f"Error in session_query_stream: {e}")
            error_chunk = StreamChunk(
                type="error",
                data=ErrorResponse(error=str(e))
            )
            yield f"data: {error_chunk.model_dump_json()}\n\n"

    return StreamingResponse(
        event_generator(),
        media_type="text/event-stream",
        headers={
            "Cache-Control": "no-cache",
            "Connection": "keep-alive",
        }
    )


@router.delete("/session/{session_id}", status_code=status.HTTP_204_NO_CONTENT)
async def delete_session(
    session_id: str,
    session_mgr: SessionManager = Depends(get_session_manager),
    db_service: DatabaseService = Depends(get_database_service),
    current_user: Optional[UserDB] = Depends(get_current_user_optional),
):
    """
    Delete an existing session
    
    Only the session owner can delete their session.
    """
    # ä»æ•°æ®åº“è·å–ä¼šè¯ï¼ˆéªŒè¯ç”¨æˆ·æƒé™ï¼‰
    # å…è®¸åˆ é™¤ä¸æ´»è·ƒçš„ä¼šè¯
    db_session = await db_service.get_session(session_id, include_inactive=True)
    if db_session is None:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail=f"Session {session_id} not found"
        )
    
    # éªŒè¯ä¼šè¯å±äºå½“å‰ç”¨æˆ·
    if current_user:
        if db_session.user_id != current_user.id:
            raise HTTPException(
                status_code=status.HTTP_403_FORBIDDEN,
                detail="You don't have permission to delete this session"
            )
    elif db_session.user_id is not None:
        # ä¼šè¯å·²ç»‘å®šç”¨æˆ·ï¼Œä½†å½“å‰è¯·æ±‚æœªè®¤è¯
        raise HTTPException(
            status_code=status.HTTP_401_UNAUTHORIZED,
            detail="Authentication required to delete this session"
        )
    
    deleted = await session_mgr.remove_session(session_id)
    if not deleted:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail=f"Session {session_id} not found"
        )
    return None


@router.get("/sessions")
async def list_sessions(
    limit: Optional[int] = None,
    offset: int = 0,
    session_mgr: SessionManager = Depends(get_session_manager),
    db_service: DatabaseService = Depends(get_database_service),
    current_user: Optional[UserDB] = Depends(get_current_user_optional),
):
    """
    List all active sessions for the current user with pagination
    
    If user is authenticated, returns only their sessions.
    If not authenticated, returns empty list.
    
    Query Parameters:
        limit: Maximum number of sessions to return (default: None, returns all)
        offset: Number of sessions to skip (default: 0)
    
    Returns:
        {
            "total": total_count,
            "limit": limit,
            "offset": offset,
            "has_more": bool,
            "sessions": [...]
        }
    """
    if not current_user:
        logger.warning("[list_sessions] No authenticated user, returning empty list")
        return {
            "total": 0,
            "limit": limit,
            "offset": offset,
            "has_more": False,
            "sessions": []
        }
    
    logger.info(f"[list_sessions] Getting sessions for user: {current_user.id} ({current_user.username}), limit={limit}, offset={offset}")
    
    # ä»æ•°æ®åº“è·å–ç”¨æˆ·çš„ä¼šè¯ï¼ˆåˆ†é¡µï¼‰
    from sqlalchemy import select, func
    from models.database import SessionDB
    
    async with db_service.async_session() as session:
        # å…ˆè·å–æ€»æ•°ï¼ˆåŒ…æ‹¬ä¸æ´»è·ƒçš„ä¼šè¯ï¼Œå› ä¸ºç”¨æˆ·å¯èƒ½æƒ³æŸ¥çœ‹å†å²ï¼‰
        count_stmt = select(func.count(SessionDB.session_id)).where(
            SessionDB.user_id == current_user.id
        )
        count_result = await session.execute(count_stmt)
        total_count = count_result.scalar() or 0
        logger.info(f"[list_sessions] Total sessions count for user {current_user.id}: {total_count}")
        
        # æŸ¥æ‰¾ç”¨æˆ·çš„æ‰€æœ‰ä¼šè¯ï¼ˆåŒ…æ‹¬ä¸æ´»è·ƒçš„ï¼‰ï¼Œæ”¯æŒåˆ†é¡µ
        stmt = select(SessionDB).where(
            SessionDB.user_id == current_user.id
        ).order_by(SessionDB.last_activity.desc())
        
        if offset > 0:
            stmt = stmt.offset(offset)
        if limit:
            stmt = stmt.limit(limit)
        
        result = await session.execute(stmt)
        db_sessions = list(result.scalars().all())
        logger.info(f"[list_sessions] Found {len(db_sessions)} sessions (offset={offset}, limit={limit}) for user {current_user.id}, total={total_count}")
    
    sessions = [
        {
            "session_id": s.session_id,
            "created_at": format_utc_timestamp(s.created_at),
            "last_activity": format_utc_timestamp(s.last_activity),
            "is_connected": s.is_connected,
            "model": s.model,
        }
        for s in db_sessions
    ]
    
    # è®¡ç®—æ˜¯å¦æœ‰æ›´å¤šæ•°æ®
    has_more = (offset + len(sessions)) < total_count if limit else False
    
    # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯ï¼ˆåªåœ¨ç¬¬ä¸€é¡µæ—¶è®¡ç®—ï¼Œé¿å…æ€§èƒ½é—®é¢˜ï¼‰
    # ç»Ÿè®¡ä¿¡æ¯åŸºäºæ‰€æœ‰ä¼šè¯ï¼Œè€Œä¸æ˜¯å½“å‰é¡µ
    stats = None
    if offset == 0:  # åªåœ¨ç¬¬ä¸€é¡µè®¡ç®—ç»Ÿè®¡ä¿¡æ¯
        total_messages = 0
        total_cost = 0.0
        
        # è·å–æ‰€æœ‰ä¼šè¯çš„æ¶ˆæ¯æ•°å’ŒèŠ±è´¹ï¼ˆåŸºäºæ‰€æœ‰ä¼šè¯ï¼Œä¸æ˜¯å½“å‰é¡µï¼‰
        from models.database import MessageDB
        async with db_service.async_session() as session:
            # è·å–ç”¨æˆ·çš„æ‰€æœ‰ä¼šè¯IDï¼ˆç”¨äºç»Ÿè®¡ï¼‰
            all_sessions_stmt = select(SessionDB.session_id).where(
                SessionDB.user_id == current_user.id
            )
            all_sessions_result = await session.execute(all_sessions_stmt)
            all_session_ids = [s[0] for s in all_sessions_result.all()]
            
            # ç»Ÿè®¡æ‰€æœ‰ä¼šè¯çš„æ¶ˆæ¯æ•°å’ŒèŠ±è´¹
            for session_id in all_session_ids:
                msg_stmt = select(MessageDB).where(MessageDB.session_id == session_id)
                msg_result = await session.execute(msg_stmt)
                messages = list(msg_result.scalars().all())
                total_messages += len(messages)
                
                # ç»Ÿè®¡èŠ±è´¹ï¼ˆä» AI æ¶ˆæ¯çš„ result_info ä¸­æå–ï¼‰
                for msg in messages:
                    if msg.role == "assistant" and msg.result_info:
                        cost = msg.result_info.get("total_cost_usd")
                        if cost is not None:
                            total_cost += float(cost)
        
        stats = {
            "total_sessions": total_count,
            "total_messages": total_messages,
            "total_cost_usd": round(total_cost, 6)
        }
    
    return {
        "total": total_count,
        "limit": limit,
        "offset": offset,
        "has_more": has_more,
        "sessions": sessions,
        "stats": stats  # åªåœ¨ç¬¬ä¸€é¡µè¿”å›ç»Ÿè®¡ä¿¡æ¯
    }


@router.get("/session/{session_id}/history")
async def get_session_history(
    session_id: str,
    limit: Optional[int] = None,
    session_mgr: SessionManager = Depends(get_session_manager),
    db_service: DatabaseService = Depends(get_database_service),
    current_user: Optional[UserDB] = Depends(get_current_user_optional),
):
    """
    Get conversation history for a session

    Returns all messages exchanged in this session.
    Only accessible by the session owner.
    """
    try:
        # ä»æ•°æ®åº“è·å–ä¼šè¯ï¼ˆéªŒè¯ç”¨æˆ·æƒé™ï¼‰
        # å…è®¸æŸ¥çœ‹ä¸æ´»è·ƒçš„ä¼šè¯ï¼ˆç”¨äºæŸ¥çœ‹å†å²è®°å½•ï¼‰
        db_session = await db_service.get_session(session_id, include_inactive=True)
        if db_session is None:
            raise HTTPException(
                status_code=status.HTTP_404_NOT_FOUND,
                detail=f"Session {session_id} not found"
            )
        
        # éªŒè¯ä¼šè¯å±äºå½“å‰ç”¨æˆ·
        if current_user:
            if db_session.user_id != current_user.id:
                raise HTTPException(
                    status_code=status.HTTP_403_FORBIDDEN,
                    detail="You don't have permission to access this session"
                )
        elif db_session.user_id is not None:
            # ä¼šè¯å·²ç»‘å®šç”¨æˆ·ï¼Œä½†å½“å‰è¯·æ±‚æœªè®¤è¯
            raise HTTPException(
                status_code=status.HTTP_401_UNAUTHORIZED,
                detail="Authentication required to access this session"
            )

        # Get history from database
        history = await session_mgr.get_session_history(session_id, limit)

        return {
            "session_id": session_id,
            "total_messages": len(history),
            "messages": history
        }

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error getting session history: {e}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=str(e)
        )


@router.get("/session/{session_id}/messages")
async def get_session_messages(
    session_id: str,
    limit: Optional[int] = None,
    offset: int = 0,
    session_mgr: SessionManager = Depends(get_session_manager),
    db_service: DatabaseService = Depends(get_database_service),
    current_user: Optional[UserDB] = Depends(get_current_user_optional),
):
    """
    Get messages for a session with pagination

    Returns paginated list of messages.
    Only accessible by the session owner.
    """
    try:
        # ä»æ•°æ®åº“è·å–ä¼šè¯ï¼ˆéªŒè¯ç”¨æˆ·æƒé™ï¼‰
        db_session = await db_service.get_session(session_id)
        if db_session is None:
            raise HTTPException(
                status_code=status.HTTP_404_NOT_FOUND,
                detail=f"Session {session_id} not found"
            )
        
        # éªŒè¯ä¼šè¯å±äºå½“å‰ç”¨æˆ·
        if current_user:
            if db_session.user_id != current_user.id:
                raise HTTPException(
                    status_code=status.HTTP_403_FORBIDDEN,
                    detail="You don't have permission to access this session"
                )
        elif db_session.user_id is not None:
            # ä¼šè¯å·²ç»‘å®šç”¨æˆ·ï¼Œä½†å½“å‰è¯·æ±‚æœªè®¤è¯
            raise HTTPException(
                status_code=status.HTTP_401_UNAUTHORIZED,
                detail="Authentication required to access this session"
            )

        # Get messages from database
        history = await session_mgr.get_session_history(session_id, limit)

        # Apply offset
        if offset > 0:
            history = history[offset:]

        return {
            "session_id": session_id,
            "offset": offset,
            "limit": limit,
            "total": len(history),
            "messages": history
        }

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error getting session messages: {e}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=str(e)
        )


@router.get("/session/{session_id}/conversation", response_model=ConversationHistoryResponse)
async def get_conversation_history(
    session_id: str,
    limit: Optional[int] = None,
    offset: int = 0,
    session_mgr: SessionManager = Depends(get_session_manager),
    db_service: DatabaseService = Depends(get_database_service),
    current_user: Optional[UserDB] = Depends(get_current_user_optional),
):
    """
    Get conversation history in frontend-compatible format with pagination
    
    Returns messages in the format expected by the frontend.
    Only accessible by the session owner.
    
    Query Parameters:
        limit: Maximum number of messages to return (default: None, returns all)
        offset: Number of messages to skip (default: 0)
    
    Returns:
        ConversationHistoryResponse with paginated messages
    """
    try:
        # ä»æ•°æ®åº“è·å–ä¼šè¯ï¼ˆéªŒè¯ç”¨æˆ·æƒé™ï¼‰
        # å…è®¸æŸ¥çœ‹ä¸æ´»è·ƒçš„ä¼šè¯ï¼ˆç”¨äºæŸ¥çœ‹å†å²è®°å½•ï¼‰
        db_session = await db_service.get_session(session_id, include_inactive=True)
        if db_session is None:
            raise HTTPException(
                status_code=status.HTTP_404_NOT_FOUND,
                detail=f"Session {session_id} not found"
            )
        
        # éªŒè¯ä¼šè¯å±äºå½“å‰ç”¨æˆ·
        if current_user:
            if db_session.user_id != current_user.id:
                raise HTTPException(
                    status_code=status.HTTP_403_FORBIDDEN,
                    detail="You don't have permission to access this session"
                )
        elif db_session.user_id is not None:
            # ä¼šè¯å·²ç»‘å®šç”¨æˆ·ï¼Œä½†å½“å‰è¯·æ±‚æœªè®¤è¯
            raise HTTPException(
                status_code=status.HTTP_401_UNAUTHORIZED,
                detail="Authentication required to access this session"
            )

        logger.info(f"[get_conversation_history] Getting messages for session {session_id}, limit={limit}, offset={offset}")
        
        # Get total count of messages (only visible messages: text, file_created, file_uploaded)
        # è®¡ç®—å¯è§æ¶ˆæ¯æ€»æ•°ï¼ˆæ’é™¤ tool_use å’Œ tool_resultï¼‰
        async with db_service.async_session() as session:
            from sqlalchemy import func, and_
            visible_types = ["text", "file_created", "file_uploaded"]
            stmt = select(func.count(MessageDB.id)).where(
                and_(
                    MessageDB.session_id == session_id,
                    MessageDB.message_type.in_(visible_types)
                )
            )
            result = await session.execute(stmt)
            total_messages_count = result.scalar() or 0
        
        # ğŸ”§ ä¿®å¤åˆ†é¡µé—®é¢˜ï¼šå…ˆè·å–è¶³å¤Ÿå¤šçš„æ¶ˆæ¯ï¼ˆåŒ…æ‹¬ tool_use å’Œ tool_resultï¼‰ï¼Œç„¶åè¿‡æ»¤åå†åˆ†é¡µ
        # å› ä¸º tool_use å’Œ tool_result éœ€è¦å…³è”åˆ° text æ¶ˆæ¯ï¼Œæ‰€ä»¥ä¸èƒ½åªæŸ¥è¯¢ text æ¶ˆæ¯
        # ç­–ç•¥ï¼šä½¿ç”¨æ›´å¤§çš„ limitï¼ˆä¼°ç®—ï¼šæ¯ä¸ªå¯è§æ¶ˆæ¯å¹³å‡æœ‰ 5-10 ä¸ª tool_use/tool_resultï¼‰
        # å¦‚æœ limit å­˜åœ¨ï¼Œä½¿ç”¨ limit * 10 æ¥ç¡®ä¿è·å–è¶³å¤Ÿçš„æ¶ˆæ¯
        # å½“ offset > 0 æ—¶ï¼Œéœ€è¦ä»å¼€å§‹è·å–åˆ° offset + limit çš„æ‰€æœ‰æ¶ˆæ¯ï¼Œä»¥ç¡®ä¿åŒ…å«æ‰€æœ‰ç›¸å…³çš„ tool_use å’Œ tool_result
        fetch_limit = None
        fetch_offset = 0
        if limit:
            # ä¼°ç®—ï¼šæ¯ä¸ªå¯è§æ¶ˆæ¯å¹³å‡æœ‰ 5-10 ä¸ª tool_use/tool_result
            # è®¡ç®—éœ€è¦è·å–çš„æ¶ˆæ¯èŒƒå›´ï¼šä»å¼€å§‹åˆ° offset + limit
            # ä½¿ç”¨ (offset + limit) * 10 æ¥ç¡®ä¿è·å–è¶³å¤Ÿçš„æ¶ˆæ¯
            fetch_limit = (offset + limit) * 10
            fetch_offset = 0  # æ€»æ˜¯ä»å¼€å§‹è·å–ï¼Œä»¥ç¡®ä¿åŒ…å«æ‰€æœ‰ç›¸å…³çš„ tool_use å’Œ tool_result
        
        # Get messages from database (with larger limit to include tool_use and tool_result)
        db_messages = await db_service.get_messages(session_id, limit=fetch_limit, offset=fetch_offset)
        
        logger.info(
            f"[get_conversation_history] Fetched {len(db_messages)} raw messages "
            f"(fetch_limit={fetch_limit}, fetch_offset={fetch_offset}, "
            f"requested_limit={limit}, requested_offset={offset})"
        )
        
        # Group messages by conversation_turn_id for pairing
        messages_by_turn: Dict[str, List] = {}
        tool_calls_by_parent: Dict[int, List] = {}  # tool_use messages by parent
        tool_results_by_tool_use: Dict[str, List] = {}  # tool_result messages by tool_use_id
        
        # First pass: collect all messages and group by turn
        for msg in db_messages:
            turn_id = msg.conversation_turn_id or "unknown"
            if turn_id not in messages_by_turn:
                messages_by_turn[turn_id] = []
            messages_by_turn[turn_id].append(msg)
            
            # Collect tool calls (tool_use messages)
            if msg.message_type == "tool_use" and msg.parent_message_id:
                if msg.parent_message_id not in tool_calls_by_parent:
                    tool_calls_by_parent[msg.parent_message_id] = []
                tool_calls_by_parent[msg.parent_message_id].append(msg)
            
            # Collect tool results (tool_result messages)
            if msg.message_type == "tool_result" and msg.extra_data:
                tool_use_id = msg.extra_data.get("tool_use_id")
                if tool_use_id:
                    if tool_use_id not in tool_results_by_tool_use:
                        tool_results_by_tool_use[tool_use_id] = []
                    tool_results_by_tool_use[tool_use_id].append(msg)
                    logger.info(
                        f"[get_conversation_history] ğŸ“¦ Collected tool_result: tool_use_id={tool_use_id[:20]}..., "
                        f"content_length={len(msg.content) if msg.content else 0}, "
                        f"content_is_none={msg.content is None}, "
                        f"content_preview={str(msg.content)[:100] if msg.content else '(empty)'}, "
                        f"conversation_turn_id={msg.conversation_turn_id}"
                    )
        
        # Convert to frontend format, grouped by conversation turns
        messages: List[HistoryMessage] = []
        file_events: List[FileEventInfo] = []  # å•ç‹¬æ”¶é›†æ–‡ä»¶äº‹ä»¶ï¼Œç”¨äºåº“æ ‡ç­¾é¡µæ˜¾ç¤º
        message_counter = {"user": 0, "assistant": 0}
        
        # Sort turns by the earliest message timestamp
        sorted_turns = sorted(
            messages_by_turn.items(),
            key=lambda x: min(m.created_at for m in x[1])
        )
        
        for turn_id, turn_messages in sorted_turns:
            # Sort messages within turn by created_at
            turn_messages.sort(key=lambda m: m.created_at)
            
            for msg in turn_messages:
                # Skip tool_use messages (they're included in tool_calls)
                if msg.message_type == "tool_use":
                    continue
                
                # Skip tool_result messages (they're included in tool_calls as output)
                # tool_result æ¶ˆæ¯ä¸åº”è¯¥æ˜¾ç¤ºåœ¨å¯¹è¯ä¸­ï¼Œå®ƒä»¬åªæ˜¯å·¥å…·æ‰§è¡Œçš„å†…éƒ¨ç»“æœ
                if msg.message_type == "tool_result":
                    continue
                
                # æ”¶é›†æ–‡ä»¶äº‹ä»¶æ¶ˆæ¯ï¼ˆå•ç‹¬è¿”å›ï¼Œä¸æ˜¾ç¤ºåœ¨å¯¹è¯æ¡†ä¸­ï¼‰
                if msg.message_type in ["file_created", "file_uploaded"]:
                    # ä» extra_data ä¸­æå–æ–‡ä»¶ä¿¡æ¯
                    extra_data = msg.extra_data or {}
                    file_event = FileEventInfo(
                        file_path=extra_data.get("file_path"),
                        file_url=extra_data.get("file_url"),
                        file_name=extra_data.get("file_name"),
                        file_size=extra_data.get("file_size"),
                        file_type=extra_data.get("file_type"),
                        conversation_turn_id=msg.conversation_turn_id,
                        created_at=format_utc_timestamp(msg.created_at),
                    )
                    file_events.append(file_event)
                    continue
                
                # è¿‡æ»¤æ‰çœ‹èµ·æ¥åƒå·¥å…·ç»“æœçš„æ¶ˆæ¯ï¼ˆå³ä½¿å®ƒä»¬è¢«é”™è¯¯åœ°ä¿å­˜ä¸º text ç±»å‹ï¼‰
                # è¿™äº›æ¶ˆæ¯é€šå¸¸æ²¡æœ‰ resultInfoï¼Œæ²¡æœ‰ tool_callsï¼Œä¸”å†…å®¹çœ‹èµ·æ¥åƒå·¥å…·è¾“å‡º
                if msg.role == "assistant" and msg.message_type == "text":
                    # æ£€æŸ¥æ˜¯å¦æ˜¯å·¥å…·ç»“æœæ¶ˆæ¯çš„ç‰¹å¾ï¼š
                    # 1. æ²¡æœ‰ resultInfoï¼ˆæ­£å¸¸çš„ AI å“åº”åº”è¯¥æœ‰ resultInfoï¼‰
                    # 2. æ²¡æœ‰å…³è”çš„ tool_callsï¼ˆæ­£å¸¸çš„ AI å“åº”å¦‚æœæœ‰å·¥å…·è°ƒç”¨ä¼šæœ‰ tool_callsï¼‰
                    # 3. å†…å®¹çœ‹èµ·æ¥åƒå·¥å…·è¾“å‡ºï¼ˆå¦‚ "Todos have been modified successfully"ï¼‰
                    has_result_info = msg.result_info is not None
                    has_tool_calls = msg.id in tool_calls_by_parent
                    content = (msg.content or "").strip()
                    
                    # å¦‚æœæ¶ˆæ¯æ²¡æœ‰ resultInfo å’Œ tool_callsï¼Œä¸”å†…å®¹çœ‹èµ·æ¥åƒå·¥å…·è¾“å‡ºï¼Œåˆ™è·³è¿‡
                    # æ³¨æ„ï¼šæ­£å¸¸çš„ AI å“åº”å³ä½¿æ²¡æœ‰å·¥å…·è°ƒç”¨ï¼Œä¹Ÿåº”è¯¥æœ‰ resultInfo
                    if not has_result_info and not has_tool_calls and content:
                        # æ£€æŸ¥å†…å®¹æ˜¯å¦åŒ¹é…å¸¸è§çš„å·¥å…·è¾“å‡ºæ¨¡å¼
                        tool_result_patterns = [
                            "Todos have been modified successfully",
                            "File created successfully",
                            "Web search results",
                            "MinIOå®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸ",
                            "ğŸ”§ é…ç½®ä¿¡æ¯:",
                            "ğŸš€ MinIOå®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸ",
                        ]
                        if any(pattern in content for pattern in tool_result_patterns):
                            logger.debug(f"[get_conversation_history] Skipping tool_result-like message: id={msg.id}, content_preview={content[:50]}")
                            continue
                
                # Generate message ID
                if msg.role == "user":
                    message_counter["user"] += 1
                    msg_id = f"user-{message_counter['user']}"
                    sender = "user"
                else:  # assistant
                    message_counter["assistant"] += 1
                    msg_id = f"ai-{message_counter['assistant']}"
                    sender = "ai"
                
                # Build message
                history_msg = HistoryMessage(
                    id=msg_id,
                    text=msg.content or "",
                    sender=sender,
                    timestamp=format_utc_timestamp(msg.created_at),
                    conversation_turn_id=msg.conversation_turn_id,
                    parent_message_id=msg.parent_message_id,
                )
                
                # Add resultInfo for AI messages if available
                if msg.role == "assistant" and msg.result_info:
                    history_msg.resultInfo = MessageResultInfo(**msg.result_info)
                
                # Add tool calls for assistant messages
                if msg.role == "assistant" and msg.id in tool_calls_by_parent:
                    # ğŸ”§ ä¿®å¤ï¼šæŒ‰åˆ›å»ºæ—¶é—´é™åºæ’åº tool_callsï¼Œç¡®ä¿æœ€æ–°çš„åœ¨å‰
                    # è¿™æ ·å‰ç«¯é€‰æ‹©æœ€åä¸€ä¸ª TodoWrite æ—¶ï¼Œä¼šå¾—åˆ°æœ€æ–°çš„çŠ¶æ€
                    sorted_tool_calls = sorted(
                        tool_calls_by_parent[msg.id],
                        key=lambda m: m.created_at,
                        reverse=True  # é™åºï¼šæœ€æ–°çš„åœ¨å‰
                    )
                    for tool_msg in sorted_tool_calls:
                        tool_use_id = tool_msg.extra_data.get("tool_use_id", "") if tool_msg.extra_data else ""
                        
                        # Find corresponding tool_result
                        tool_output = None
                        if tool_use_id and tool_use_id in tool_results_by_tool_use:
                            # Get the first tool_result for this tool_use_id
                            tool_result_msg = tool_results_by_tool_use[tool_use_id][0]
                            # ğŸ” é‡è¦ï¼šå³ä½¿ content æ˜¯ç©ºå­—ç¬¦ä¸²ï¼Œä¹Ÿè§†ä¸ºæœ‰è¾“å‡ºï¼ˆå·¥å…·å·²æ‰§è¡Œå®Œæˆï¼‰
                            # åªæœ‰ content ä¸º None æ—¶æ‰è¡¨ç¤ºå·¥å…·æœªæ‰§è¡Œå®Œæˆ
                            tool_output = tool_result_msg.content
                            logger.info(
                                f"[get_conversation_history] âœ… Found tool_result: tool_use_id={tool_use_id[:20]}..., "
                                f"tool_name={tool_msg.extra_data.get('tool_name', '') if tool_msg.extra_data else ''}, "
                                f"content_type={type(tool_output).__name__}, "
                                f"content_length={len(tool_output) if tool_output else 0}, "
                                f"content_is_none={tool_output is None}, "
                                f"content_preview={str(tool_output)[:100] if tool_output else '(empty)'}, "
                                f"tool_result_turn_id={tool_result_msg.conversation_turn_id}, "
                                f"tool_use_turn_id={tool_msg.conversation_turn_id}"
                            )
                        else:
                            logger.warning(
                                f"[get_conversation_history] âŒ No tool_result found: tool_use_id={tool_use_id[:20] if tool_use_id else 'None'}..., "
                                f"tool_name={tool_msg.extra_data.get('tool_name', '') if tool_msg.extra_data else ''}, "
                                f"available_tool_use_ids={[k[:20] + '...' for k in list(tool_results_by_tool_use.keys())[:10]]}, "
                                f"total_tool_results={len(tool_results_by_tool_use)}"
                            )
                        
                        # è·å–åŸå§‹ tool_input
                        raw_tool_input = tool_msg.extra_data.get("tool_input", {}) if tool_msg.extra_data else {}
                        tool_name = tool_msg.extra_data.get("tool_name", "") if tool_msg.extra_data else ""
                        
                        # ğŸ”§ ä¿®å¤ï¼šå¯¹äº TodoWrite å·¥å…·è°ƒç”¨ï¼Œæ¸…ç†å·²å®Œæˆä»»åŠ¡çš„ activeForm å­—æ®µ
                        # activeForm åªåœ¨ in_progress çŠ¶æ€æ—¶æ‰æœ‰æ„ä¹‰ï¼Œcompleted çŠ¶æ€åº”è¯¥æ¸…é™¤
                        cleaned_tool_input = raw_tool_input
                        if tool_name == "TodoWrite" and isinstance(raw_tool_input, dict):
                            todos = raw_tool_input.get("todos", [])
                            if isinstance(todos, list) and len(todos) > 0:
                                cleaned_todos = []
                                for todo in todos:
                                    if isinstance(todo, dict):
                                        todo_status = todo.get("status", "pending")
                                        cleaned_todo = todo.copy()
                                        # å¦‚æœä»»åŠ¡çŠ¶æ€æ˜¯ completedï¼Œæ¸…é™¤ activeForm å­—æ®µ
                                        if todo_status == "completed" and "activeForm" in cleaned_todo:
                                            del cleaned_todo["activeForm"]
                                        cleaned_todos.append(cleaned_todo)
                                    else:
                                        cleaned_todos.append(todo)
                                cleaned_tool_input = raw_tool_input.copy()
                                cleaned_tool_input["todos"] = cleaned_todos
                        
                        tool_info = ToolCallInfo(
                            tool_use_id=tool_use_id,
                            tool_name=tool_name,
                            tool_input=cleaned_tool_input,
                            tool_output=tool_output,  # å¯èƒ½æ˜¯ Noneã€ç©ºå­—ç¬¦ä¸²æˆ–å®é™…å†…å®¹
                            conversation_turn_id=tool_msg.conversation_turn_id,  # ä½¿ç”¨å·¥å…·è°ƒç”¨æ¶ˆæ¯æœ¬èº«çš„ conversation_turn_id
                        )
                        history_msg.tool_calls.append(tool_info)
                
                messages.append(history_msg)

        # ğŸ”§ ä¿®å¤åˆ†é¡µï¼šå¯¹è¿‡æ»¤åçš„æ¶ˆæ¯è¿›è¡Œåˆ†é¡µ
        # å¦‚æœæŒ‡å®šäº† limit å’Œ offsetï¼Œåªè¿”å›å¯¹åº”çš„å¯è§æ¶ˆæ¯
        if limit is not None:
            # å¯¹è¿‡æ»¤åçš„æ¶ˆæ¯è¿›è¡Œåˆ†é¡µ
            start_idx = offset
            end_idx = offset + limit
            paginated_messages = messages[start_idx:end_idx]
            logger.info(
                f"[get_conversation_history] Paginated messages: "
                f"total_filtered={len(messages)}, "
                f"offset={offset}, limit={limit}, "
                f"returned={len(paginated_messages)}"
            )
            messages = paginated_messages

        # è®¡ç®—æ˜¯å¦æœ‰æ›´å¤šæ•°æ®
        # æ³¨æ„ï¼štotal_messages_count æ˜¯å¯è§æ¶ˆæ¯çš„æ€»æ•°ï¼ˆå·²æ’é™¤ tool_use å’Œ tool_resultï¼‰
        has_more = (offset + len(messages)) < total_messages_count if limit else False

        return ConversationHistoryResponse(
            session_id=session_id,
            messages=messages,
            file_events=file_events,
            total=total_messages_count,
            limit=limit,
            offset=offset,
            has_more=has_more
        )

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error getting conversation history: {e}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=str(e)
        )


@router.delete("/message/{message_id}", status_code=status.HTTP_204_NO_CONTENT)
async def delete_message(
    message_id: int,
    db_service: DatabaseService = Depends(get_database_service),
):
    """
    Delete a message by its ID
    """
    try:
        success = await db_service.delete_message(message_id)
        if not success:
            raise HTTPException(
                status_code=status.HTTP_404_NOT_FOUND,
                detail=f"Message {message_id} not found"
            )
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error deleting message {message_id}: {e}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=str(e)
        )


@router.get("/health")
async def health_check():
    """Health check endpoint"""
    return {"status": "healthy"}


@router.get("/file/content")
async def get_file_content(
    file_path: str,
    current_user: Optional[UserDB] = Depends(get_current_user_optional),
):
    """
    è¯»å–æ–‡ä»¶å†…å®¹

    æ‰€æœ‰æ–‡ä»¶å¿…é¡»åœ¨ aigc/work_dir ç›®å½•ä¸‹

    Args:
        file_path: æ–‡ä»¶è·¯å¾„ï¼ˆç›¸å¯¹äº aigc/work_dirï¼Œä¾‹å¦‚ï¼šreports/file.mdï¼‰

    Returns:
        æ–‡ä»¶å†…å®¹ï¼ˆæ–‡æœ¬æ–‡ä»¶ï¼‰æˆ–é”™è¯¯ä¿¡æ¯
    """
    import os
    from pathlib import Path
    from core.config import settings

    try:
        # å®‰å…¨æ£€æŸ¥ï¼šé˜²æ­¢è·¯å¾„éå†æ”»å‡»
        file_path = os.path.normpath(file_path)
        if file_path.startswith('/') or file_path.startswith('..'):
            raise HTTPException(
                status_code=status.HTTP_400_BAD_REQUEST,
                detail="Invalid file path: must be relative to work_dir"
            )

        # æ„å»ºå®Œæ•´è·¯å¾„ï¼šaigc/work_dir/file_path
        full_path = settings.work_dir / file_path

        logger.info(f"[get_file_content] Reading file: {full_path}")

        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not full_path.exists():
            raise HTTPException(
                status_code=status.HTTP_404_NOT_FOUND,
                detail=f"File not found: {file_path} (in {settings.work_dir})"
            )

        # æ£€æŸ¥æ˜¯å¦ä¸ºæ–‡ä»¶ï¼ˆä¸æ˜¯ç›®å½•ï¼‰
        if not full_path.is_file():
            raise HTTPException(
                status_code=status.HTTP_400_BAD_REQUEST,
                detail="Path is not a file"
            )

        # è¯»å–æ–‡ä»¶å†…å®¹
        try:
            content = full_path.read_text(encoding='utf-8')
            return {
                "file_path": file_path,
                "content": content,
                "size": full_path.stat().st_size
            }
        except UnicodeDecodeError:
            # å¦‚æœä¸æ˜¯æ–‡æœ¬æ–‡ä»¶ï¼Œè¿”å›é”™è¯¯
            raise HTTPException(
                status_code=status.HTTP_400_BAD_REQUEST,
                detail="File is not a text file or encoding is not UTF-8"
            )
    
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error reading file {file_path}: {e}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=str(e)
        )
@router.get("/conversation/{conversation_turn_id}/dataflow", response_model=DataFlowResponse)
async def get_conversation_dataflow(
    conversation_turn_id: str,
    session_mgr: SessionManager = Depends(get_session_manager),
    db_service: DatabaseService = Depends(get_database_service),
    current_user: Optional[UserDB] = Depends(get_current_user_optional),
):
    """
    è·å– conversation_turn_id çš„å®Œæ•´æ•°æ®é“¾è·¯
    
    è¿”å›è¯¥å¯¹è¯è½®æ¬¡çš„æ‰€æœ‰èŠ‚ç‚¹ï¼ˆç”¨æˆ·æ¶ˆæ¯ã€å·¥å…·è°ƒç”¨ã€å·¥å…·ç»“æœã€AIå“åº”ã€æ–‡ä»¶äº‹ä»¶ç­‰ï¼‰
    ä»¥åŠå®ƒä»¬ä¹‹é—´çš„çˆ¶å­å…³ç³»ï¼Œç”¨äºå‰ç«¯å¯è§†åŒ–å±•ç¤º
    """
    try:
        # æŸ¥è¯¢è¯¥ conversation_turn_id çš„æ‰€æœ‰æ¶ˆæ¯
        from sqlalchemy import select
        from models.database import MessageDB
        
        logger.info(f"[get_conversation_dataflow] Querying messages for conversation_turn_id: {conversation_turn_id}")
        
        # å…ˆéªŒè¯æƒé™ï¼šé€šè¿‡ conversation_turn_id æ‰¾åˆ° sessionï¼Œç„¶åéªŒè¯ç”¨æˆ·æƒé™
        # è¿™æ ·å¯ä»¥ç¡®ä¿ç”¨æˆ·åªèƒ½è®¿é—®è‡ªå·±çš„æ•°æ®
        async with db_service.async_session() as session:
            # å…ˆè·å–ä¸€æ¡æ¶ˆæ¯ä»¥æ‰¾åˆ° session_id
            stmt = select(MessageDB).where(
                MessageDB.conversation_turn_id == conversation_turn_id
            ).limit(1)
            result = await session.execute(stmt)
            first_message = result.scalar_one_or_none()
            
            if not first_message:
                logger.warning(f"[get_conversation_dataflow] No messages found for conversation_turn_id: {conversation_turn_id}")
                raise HTTPException(
                    status_code=status.HTTP_404_NOT_FOUND,
                    detail=f"No messages found for conversation_turn_id: {conversation_turn_id}"
                )
            
            session_id = first_message.session_id
            
            # éªŒè¯æƒé™ï¼ˆåŒ…å« inactive sessionsï¼Œå› ä¸ºå¯èƒ½æ˜¯å†å²æ•°æ®ï¼‰
            db_session = await db_service.get_session(session_id, include_inactive=True)
            if db_session is None:
                logger.warning(f"[get_conversation_dataflow] Session {session_id} not found for conversation_turn_id: {conversation_turn_id}")
                raise HTTPException(
                    status_code=status.HTTP_404_NOT_FOUND,
                    detail=f"Session {session_id} not found"
                )
            
            # éªŒè¯ç”¨æˆ·æƒé™ï¼šç¡®ä¿åªèƒ½è®¿é—®è‡ªå·±çš„ä¼šè¯
            if current_user:
                if db_session.user_id != current_user.id:
                    logger.warning(f"[get_conversation_dataflow] User {current_user.id} attempted to access session {session_id} owned by user {db_session.user_id}")
                    raise HTTPException(
                        status_code=status.HTTP_403_FORBIDDEN,
                        detail="You don't have permission to access this session"
                    )
            elif db_session.user_id is not None:
                raise HTTPException(
                    status_code=status.HTTP_401_UNAUTHORIZED,
                    detail="Authentication required to access this session"
                )
            
            # æƒé™éªŒè¯é€šè¿‡åï¼Œè·å–æ‰€æœ‰æ¶ˆæ¯
            stmt = select(MessageDB).where(
                MessageDB.conversation_turn_id == conversation_turn_id
            ).order_by(MessageDB.created_at)
            result = await session.execute(stmt)
            messages = list(result.scalars().all())
        
        logger.info(f"[get_conversation_dataflow] Found {len(messages)} messages for conversation_turn_id: {conversation_turn_id} (user_id: {current_user.id if current_user else None})")
        
        # æ„å»ºèŠ‚ç‚¹æ˜ å°„
        nodes: List[DataFlowNode] = []
        node_map: Dict[str, DataFlowNode] = {}
        tool_use_id_to_node_id: Dict[str, str] = {}  # tool_use_id -> node_id
        
        # ğŸ” å»é‡é€»è¾‘ï¼šè¿½è¸ªå·²å¤„ç†çš„èŠ‚ç‚¹ï¼Œé¿å…é‡å¤
        processed_tool_use_ids = set()  # å·²å¤„ç†çš„ tool_use_idï¼ˆtool_use å’Œ tool_resultï¼‰
        processed_assistant_messages = {}  # å·²å¤„ç†çš„ assistant_message (parent_message_id -> æœ€æ–°æ¶ˆæ¯)
        
        # ç¬¬ä¸€éï¼šåˆ›å»ºæ‰€æœ‰èŠ‚ç‚¹ï¼ˆå¸¦å»é‡é€»è¾‘ï¼‰
        for msg in messages:
            node_id = str(msg.id)
            node_type = msg.message_type
            node_name = ""
            content_preview = None
            extra_data = msg.extra_data or {}
            
            # æ ¹æ®æ¶ˆæ¯ç±»å‹è®¾ç½®èŠ‚ç‚¹åç§°å’Œå†…å®¹
            if msg.role == "user" and msg.message_type == "text":
                node_type = "user_message"
                node_name = "ç”¨æˆ·æ¶ˆæ¯"
                content_preview = (msg.content or "")[:100] if msg.content else None
            elif msg.role == "assistant":
                if msg.message_type == "text":
                    node_type = "assistant_message"
                    node_name = "AIå“åº”"
                    content_preview = (msg.content or "")[:100] if msg.content else None
                elif msg.message_type == "tool_use":
                    node_type = "tool_use"
                    node_name = extra_data.get("tool_name", "æœªçŸ¥å·¥å…·")
                    tool_use_id = extra_data.get("tool_use_id", "")
                    if tool_use_id:
                        tool_use_id_to_node_id[tool_use_id] = node_id
                    extra_data = {
                        "tool_use_id": tool_use_id,
                        "tool_name": node_name,
                        "tool_input": extra_data.get("tool_input", {}),
                    }
                elif msg.message_type == "tool_result":
                    node_type = "tool_result"
                    tool_use_id = extra_data.get("tool_use_id", "")
                    # å°è¯•ä» tool_use_id_to_node_id è·å–å·¥å…·åç§°ï¼ˆåœ¨ç¬¬äºŒééå†æ—¶æ›´æ–°ï¼‰
                    tool_use_node_id = tool_use_id_to_node_id.get(tool_use_id)
                    if tool_use_node_id:
                        node_name = f"å·¥å…·ç»“æœ ({tool_use_id[:8]}...)"
                    else:
                        node_name = "å·¥å…·ç»“æœ"
                    content_preview = (msg.content or "")[:100] if msg.content else None
                elif msg.message_type in ["file_created", "file_uploaded"]:
                    node_type = "file_event"
                    node_name = "æ–‡ä»¶åˆ›å»º" if msg.message_type == "file_created" else "æ–‡ä»¶ä¸Šä¼ "
                    extra_data = {
                        "file_path": extra_data.get("file_path"),
                        "file_url": extra_data.get("file_url"),
                        "file_name": extra_data.get("file_name"),
                        "file_size": extra_data.get("file_size"),
                        "file_type": extra_data.get("file_type"),
                    }
            
            # ç¡®å®šçˆ¶èŠ‚ç‚¹ID
            parent_node_id = None
            if msg.parent_message_id:
                parent_node_id = str(msg.parent_message_id)
            elif msg.message_type == "tool_result":
                # tool_result çš„çˆ¶èŠ‚ç‚¹æ˜¯å¯¹åº”çš„ tool_use
                tool_use_id = extra_data.get("tool_use_id", "")
                parent_node_id = tool_use_id_to_node_id.get(tool_use_id)
            
            node = DataFlowNode(
                node_id=node_id,
                node_type=node_type,
                node_name=node_name,
                timestamp=format_utc_timestamp(msg.created_at),
                content_preview=content_preview,
                extra_data=extra_data if extra_data else None,
                parent_node_id=parent_node_id,
                children_node_ids=[],
            )
            nodes.append(node)
            node_map[node_id] = node
        
        # ç¬¬äºŒéï¼šå»ºç«‹çˆ¶å­å…³ç³»å’Œæ›´æ–°å·¥å…·ç»“æœåç§°
        root_node_id = None
        for node in nodes:
            # æ›´æ–°å·¥å…·ç»“æœçš„åç§°ï¼ˆç°åœ¨ node_map å·²ç»å®Œæ•´ï¼‰
            if node.node_type == "tool_result" and node.extra_data:
                tool_use_id = node.extra_data.get("tool_use_id", "")
                tool_use_node_id = tool_use_id_to_node_id.get(tool_use_id)
                if tool_use_node_id and tool_use_node_id in node_map:
                    tool_name = node_map[tool_use_node_id].node_name
                    node.node_name = f"{tool_name} ç»“æœ"
            
            # å»ºç«‹çˆ¶å­å…³ç³»
            if node.parent_node_id and node.parent_node_id in node_map:
                parent_node = node_map[node.parent_node_id]
                if node.node_id not in parent_node.children_node_ids:
                    parent_node.children_node_ids.append(node.node_id)
            elif node.node_type == "user_message":
                # ç”¨æˆ·æ¶ˆæ¯æ˜¯æ ¹èŠ‚ç‚¹
                root_node_id = node.node_id
        
        return DataFlowResponse(
            conversation_turn_id=conversation_turn_id,
            session_id=session_id,
            nodes=nodes,
            root_node_id=root_node_id,
        )
    
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error getting conversation dataflow: {e}", exc_info=True)
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=str(e)
    )


@router.get("/files/session/{session_id}")
async def get_session_files(
    session_id: str,
    current_user: Optional[UserDB] = Depends(get_current_user_optional),
    db_service: DatabaseService = Depends(get_database_service),
):
    """
    Get all files for a session (for @mention functionality)
    
    Returns a list of files uploaded in the session, suitable for
    displaying in a file selection dropdown when user types "@".
    """
    if not current_user:
        raise HTTPException(status_code=401, detail="Authentication required")
    
    # Verify session belongs to current user
    db_session = await db_service.get_session(session_id)
    if not db_session:
        raise HTTPException(status_code=404, detail="Session not found")
    
    if db_session.user_id != current_user.id:
        raise HTTPException(status_code=403, detail="Permission denied")
    
    # Get session files
    file_search_service = FileSearchService(db_service)
    files = await file_search_service.get_session_files(
        session_id=session_id,
        user_id=current_user.id,
    )
    
    # Convert to response format
    return {
        "files": [
            {
                "doc_id": file.doc_id,
                "file_name": file.file_name,
                "file_type": file.file_type,
                "file_size": file.file_size,
                "uploaded_at": format_utc_timestamp(file.uploaded_at) if file.uploaded_at else None,
            }
            for file in files
        ]
    }


@router.post("/frontend/log", response_model=FrontendLogResponse)
async def log_frontend(
    log_request: FrontendLogRequest,
    current_user: Optional[UserDB] = Depends(get_current_user_optional)
):
    """
    æ¥æ”¶å‰ç«¯æ—¥å¿—å¹¶å†™å…¥åˆ° logs/frontend.log æ–‡ä»¶
    
    å‰ç«¯å¯ä»¥é€šè¿‡è¿™ä¸ªæ¥å£å°† console æ—¥å¿—å‘é€åˆ°åç«¯ï¼Œåç«¯ä¼šå°†å…¶å†™å…¥æ—¥å¿—æ–‡ä»¶
    """
    from pathlib import Path
    from datetime import datetime
    import json
    
    try:
        # è·å–é¡¹ç›®æ ¹ç›®å½•
        # æ–¹æ³•ï¼šä» backend/api/v1/endpoints.py å‘ä¸Š4çº§åˆ°é¡¹ç›®æ ¹ç›®å½•
        # __file__ = /Users/hehe/pycharm_projects/aigc/backend/api/v1/endpoints.py
        # parent = backend/api/v1
        # parent.parent = backend/api
        # parent.parent.parent = backend
        # parent.parent.parent.parent = é¡¹ç›®æ ¹ç›®å½• (aigc)
        current_file = Path(__file__).resolve()  # ä½¿ç”¨ resolve() è·å–ç»å¯¹è·¯å¾„
        project_root = current_file.parent.parent.parent.parent
        log_file_path = project_root / "logs" / "frontend.log"
        
        # ç¡®ä¿ logs ç›®å½•å­˜åœ¨
        log_file_path.parent.mkdir(parents=True, exist_ok=True)
        
        # æ ¼å¼åŒ–æ—¥å¿—æ¶ˆæ¯
        timestamp = log_request.timestamp or datetime.now().isoformat()
        level = log_request.level.upper()
        
        # æ„å»ºæ—¥å¿—è¡Œ
        log_parts = [
            f"[{timestamp}]",
            f"[{level}]",
            f"[{log_request.source}]",
            log_request.message
        ]
        
        # å¦‚æœæœ‰é¢å¤–æ•°æ®ï¼Œæ·»åŠ åˆ°æ—¥å¿—ä¸­
        if log_request.data is not None:
            try:
                data_str = json.dumps(log_request.data, ensure_ascii=False, indent=2)
                log_parts.append(f"\nData: {data_str}")
            except (TypeError, ValueError):
                log_parts.append(f"\nData: {str(log_request.data)}")
        
        log_line = " ".join(log_parts) + "\n"
        
        # å†™å…¥æ—¥å¿—æ–‡ä»¶ï¼ˆè¿½åŠ æ¨¡å¼ï¼‰
        with open(log_file_path, "a", encoding="utf-8") as f:
            f.write(log_line)
        
        return FrontendLogResponse(
            success=True,
            message="Log written successfully"
        )
        
    except Exception as e:
        # ä¸è®°å½•é”™è¯¯åˆ° backend.logï¼Œä»…è¿”å›é”™è¯¯å“åº”
        return FrontendLogResponse(
            success=False,
            message=f"Error writing log: {str(e)}"
        )


# =========================================================================
# Phase 3: åé¦ˆæ”¶é›† API
# =========================================================================

@router.post("/feedback")
async def submit_feedback(
    message_id: Optional[int] = None,
    session_id: Optional[str] = None,
    conversation_turn_id: Optional[str] = None,
    feedback_type: str = "like",  # 'like' | 'dislike' | 'correct' | 'regenerate' | 'implicit_retry' | 'implicit_modify'
    feedback_data: Optional[Dict] = None,
    user_prompt: Optional[str] = None,
    assistant_response: Optional[str] = None,
    scenario_ids: Optional[List[str]] = None,
    current_user: Optional[UserDB] = Depends(get_current_user_optional),
    db_service: DatabaseService = Depends(get_database_service),
):
    """
    æäº¤ç”¨æˆ·åé¦ˆ
    
    æ”¯æŒæ˜¾å¼åé¦ˆï¼ˆç‚¹èµ/ç‚¹è¸©/çº æ­£/é‡æ–°ç”Ÿæˆï¼‰å’Œéšå¼åé¦ˆï¼ˆé‡æ–°æé—®ã€ä¿®æ”¹é—®é¢˜ç­‰ï¼‰
    """
    try:
        feedback_collector = FeedbackCollector(db_service)
        
        user_id = current_user.id if current_user else None
        
        feedback = await feedback_collector.collect_feedback(
            user_id=user_id,
            session_id=session_id,
            message_id=message_id,
            conversation_turn_id=conversation_turn_id,
            feedback_type=feedback_type,
            feedback_data=feedback_data,
            user_prompt=user_prompt,
            assistant_response=assistant_response,
            scenario_ids=scenario_ids
        )
        
        logger.info(
            f"[submit_feedback] åé¦ˆæäº¤æˆåŠŸ: user_id={user_id}, "
            f"session_id={session_id}, type={feedback_type}"
        )
        
        return {
            "success": True,
            "feedback_id": feedback.id,
            "message": "åé¦ˆå·²æäº¤"
        }
        
    except Exception as e:
        logger.error(f"Error submitting feedback: {e}", exc_info=True)
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Failed to submit feedback: {str(e)}"
        )


@router.post("/feedback/implicit")
async def submit_implicit_feedback(
    session_id: Optional[str] = None,
    implicit_type: str = "retry",  # 'retry' | 'modify' | 'regenerate'
    original_prompt: Optional[str] = None,
    modified_prompt: Optional[str] = None,
    context: Optional[Dict] = None,
    current_user: Optional[UserDB] = Depends(get_current_user_optional),
    db_service: DatabaseService = Depends(get_database_service),
):
    """
    æäº¤éšå¼åé¦ˆï¼ˆç”¨æˆ·é‡æ–°æé—®ã€ä¿®æ”¹é—®é¢˜ç­‰ï¼‰
    """
    try:
        feedback_collector = FeedbackCollector(db_service)
        
        user_id = current_user.id if current_user else None
        
        feedback = await feedback_collector.collect_implicit_feedback(
            user_id=user_id,
            session_id=session_id,
            implicit_type=implicit_type,
            original_prompt=original_prompt,
            modified_prompt=modified_prompt,
            context=context
        )
        
        logger.info(
            f"[submit_implicit_feedback] éšå¼åé¦ˆæäº¤æˆåŠŸ: user_id={user_id}, "
            f"session_id={session_id}, type={implicit_type}"
        )
        
        return {
            "success": True,
            "feedback_id": feedback.id,
            "message": "éšå¼åé¦ˆå·²æäº¤"
        }
        
    except Exception as e:
        logger.error(f"Error submitting implicit feedback: {e}", exc_info=True)
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Failed to submit implicit feedback: {str(e)}"
        )

